{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "cnn_vae.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harvey2phase/rrh-MNIST/blob/main/cnn_vae.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nlBt0FWz8iXu"
      },
      "source": [
        "import os\n",
        "import urllib\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.utils\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import MNIST\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "\n",
        "import seaborn as sns"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2JmIrFw-0GXL"
      },
      "source": [
        "sns.set()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TFpBblS_eLg1"
      },
      "source": [
        "GPU = True\n",
        "device = torch.device(\"cuda:0\" if GPU and torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hfwhdEx46mFx"
      },
      "source": [
        "# Load MNIST"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o8UxKtJy51hY"
      },
      "source": [
        "MAX_ROT_DEG = 15\n",
        "BATCH_SIZE = 128"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R9VbzfzV47ON"
      },
      "source": [
        "img_transform = transforms.Compose([\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "rot_transform = transforms.RandomRotation(MAX_ROT_DEG)\n",
        "\n",
        "def load_mnist(train, batch_size = BATCH_SIZE):\n",
        "    dataset = MNIST(\n",
        "        root = './data/MNIST',\n",
        "        download = True,\n",
        "        train = train,\n",
        "        transform = img_transform,\n",
        "    )\n",
        "    return DataLoader(dataset, batch_size = batch_size, shuffle = True)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "48Re9M0QYHy8"
      },
      "source": [
        "train_dataloader = load_mnist(train = True)\n",
        "test_dataloader = load_mnist(train = False)"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0IMlt_q67tJo"
      },
      "source": [
        "# Place into numpy arrays for easier manipulation\n",
        "traindata = list(train_dataloader)\n",
        "traindata = [[sample[0].numpy(), sample[1].numpy()] for sample in traindata]\n",
        "train_X = np.vstack([sample[0] for sample in traindata])\n",
        "train_y = np.hstack([sample[1] for sample in traindata])\n",
        "\n",
        "testdata = list(test_dataloader)\n",
        "testdata = [[sample[0].numpy(), sample[1].numpy()] for sample in testdata]\n",
        "test_X = np.vstack([sample[0] for sample in testdata])\n",
        "test_y = np.hstack([sample[1] for sample in testdata])"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ugFXXKS40L21"
      },
      "source": [
        "# Model Definitions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tMvoDB4Pz-fN"
      },
      "source": [
        "## CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hQxQ4mV866aL"
      },
      "source": [
        "CNN_TRAIN_BATCH_SIZE = 64\n",
        "CNN_TEST_BATCH_SIZE = 1000\n",
        "CNN_EPOCHS = 14\n",
        "LR = 1.0\n",
        "GAMMA = 0.7\n",
        "LOG_INT = 10"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vSlDXhl-77_a"
      },
      "source": [
        "cnn_train_dataloader = load_mnist(True, batch_size = CNN_TRAIN_BATCH_SIZE)\n",
        "cnn_test_dataloader = load_mnist(False, batch_size = CNN_TEST_BATCH_SIZE)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zw9LQeR8z__y"
      },
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
        "        self.dropout1 = nn.Dropout(0.25)\n",
        "        self.dropout2 = nn.Dropout(0.5)\n",
        "        self.fc1 = nn.Linear(9216, 128)\n",
        "        self.fc2 = nn.Linear(128, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.hidden_layers(x)\n",
        "        output = F.log_softmax(x, dim=1)\n",
        "        return output\n",
        "\n",
        "    def hidden_layers(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv2(x)\n",
        "        x = F.relu(x)\n",
        "        x = F.max_pool2d(x, 2)\n",
        "        x = self.dropout1(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.fc1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.dropout2(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "def train(\n",
        "    model,\n",
        "    optimizer,\n",
        "    device = device,\n",
        "    train_loader = cnn_train_dataloader,\n",
        "    epoch = 14\n",
        "):\n",
        "    model.train()\n",
        "    \n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = F.nll_loss(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if batch_idx % LOG_INT == 0:\n",
        "            print(\n",
        "                'Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                    epoch,\n",
        "                    batch_idx * len(data),\n",
        "                    len(train_loader.dataset),\n",
        "                    100. * batch_idx / len(train_loader), loss.item(),\n",
        "                )\n",
        "            )\n",
        "\n",
        "def test(model, device = device, test_loader = cnn_test_dataloader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
        "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        100. * correct / len(test_loader.dataset)))"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m_tg2DAD7U3w",
        "outputId": "d39ef25e-cc57-4cfb-c8f6-fa3b1cd5b909"
      },
      "source": [
        "cnn = Net().to(device)\n",
        "optimizer = torch.optim.Adadelta(cnn.parameters(), lr=LR)\n",
        "\n",
        "scheduler = StepLR(optimizer, step_size=1, gamma=GAMMA)\n",
        "for epoch in range(1, CNN_EPOCHS + 1):\n",
        "    train(cnn, optimizer)\n",
        "    test(cnn)\n",
        "    scheduler.step()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 14 [0/60000 (0%)]\tLoss: 2.301177\n",
            "Train Epoch: 14 [640/60000 (1%)]\tLoss: 1.687119\n",
            "Train Epoch: 14 [1280/60000 (2%)]\tLoss: 1.033114\n",
            "Train Epoch: 14 [1920/60000 (3%)]\tLoss: 1.040087\n",
            "Train Epoch: 14 [2560/60000 (4%)]\tLoss: 0.647828\n",
            "Train Epoch: 14 [3200/60000 (5%)]\tLoss: 0.433177\n",
            "Train Epoch: 14 [3840/60000 (6%)]\tLoss: 0.495353\n",
            "Train Epoch: 14 [4480/60000 (7%)]\tLoss: 0.234113\n",
            "Train Epoch: 14 [5120/60000 (9%)]\tLoss: 0.335003\n",
            "Train Epoch: 14 [5760/60000 (10%)]\tLoss: 0.338624\n",
            "Train Epoch: 14 [6400/60000 (11%)]\tLoss: 0.287689\n",
            "Train Epoch: 14 [7040/60000 (12%)]\tLoss: 0.340375\n",
            "Train Epoch: 14 [7680/60000 (13%)]\tLoss: 0.411564\n",
            "Train Epoch: 14 [8320/60000 (14%)]\tLoss: 0.397025\n",
            "Train Epoch: 14 [8960/60000 (15%)]\tLoss: 0.259148\n",
            "Train Epoch: 14 [9600/60000 (16%)]\tLoss: 0.204252\n",
            "Train Epoch: 14 [10240/60000 (17%)]\tLoss: 0.190183\n",
            "Train Epoch: 14 [10880/60000 (18%)]\tLoss: 0.225776\n",
            "Train Epoch: 14 [11520/60000 (19%)]\tLoss: 0.183133\n",
            "Train Epoch: 14 [12160/60000 (20%)]\tLoss: 0.139476\n",
            "Train Epoch: 14 [12800/60000 (21%)]\tLoss: 0.230065\n",
            "Train Epoch: 14 [13440/60000 (22%)]\tLoss: 0.055556\n",
            "Train Epoch: 14 [14080/60000 (23%)]\tLoss: 0.361124\n",
            "Train Epoch: 14 [14720/60000 (25%)]\tLoss: 0.111099\n",
            "Train Epoch: 14 [15360/60000 (26%)]\tLoss: 0.164769\n",
            "Train Epoch: 14 [16000/60000 (27%)]\tLoss: 0.402161\n",
            "Train Epoch: 14 [16640/60000 (28%)]\tLoss: 0.110807\n",
            "Train Epoch: 14 [17280/60000 (29%)]\tLoss: 0.224756\n",
            "Train Epoch: 14 [17920/60000 (30%)]\tLoss: 0.103907\n",
            "Train Epoch: 14 [18560/60000 (31%)]\tLoss: 0.142270\n",
            "Train Epoch: 14 [19200/60000 (32%)]\tLoss: 0.238689\n",
            "Train Epoch: 14 [19840/60000 (33%)]\tLoss: 0.119147\n",
            "Train Epoch: 14 [20480/60000 (34%)]\tLoss: 0.113424\n",
            "Train Epoch: 14 [21120/60000 (35%)]\tLoss: 0.118386\n",
            "Train Epoch: 14 [21760/60000 (36%)]\tLoss: 0.211753\n",
            "Train Epoch: 14 [22400/60000 (37%)]\tLoss: 0.065894\n",
            "Train Epoch: 14 [23040/60000 (38%)]\tLoss: 0.075985\n",
            "Train Epoch: 14 [23680/60000 (39%)]\tLoss: 0.096018\n",
            "Train Epoch: 14 [24320/60000 (41%)]\tLoss: 0.331373\n",
            "Train Epoch: 14 [24960/60000 (42%)]\tLoss: 0.040898\n",
            "Train Epoch: 14 [25600/60000 (43%)]\tLoss: 0.292252\n",
            "Train Epoch: 14 [26240/60000 (44%)]\tLoss: 0.068378\n",
            "Train Epoch: 14 [26880/60000 (45%)]\tLoss: 0.194674\n",
            "Train Epoch: 14 [27520/60000 (46%)]\tLoss: 0.043527\n",
            "Train Epoch: 14 [28160/60000 (47%)]\tLoss: 0.237247\n",
            "Train Epoch: 14 [28800/60000 (48%)]\tLoss: 0.240949\n",
            "Train Epoch: 14 [29440/60000 (49%)]\tLoss: 0.205234\n",
            "Train Epoch: 14 [30080/60000 (50%)]\tLoss: 0.299734\n",
            "Train Epoch: 14 [30720/60000 (51%)]\tLoss: 0.136201\n",
            "Train Epoch: 14 [31360/60000 (52%)]\tLoss: 0.298832\n",
            "Train Epoch: 14 [32000/60000 (53%)]\tLoss: 0.104890\n",
            "Train Epoch: 14 [32640/60000 (54%)]\tLoss: 0.065198\n",
            "Train Epoch: 14 [33280/60000 (55%)]\tLoss: 0.051474\n",
            "Train Epoch: 14 [33920/60000 (57%)]\tLoss: 0.156020\n",
            "Train Epoch: 14 [34560/60000 (58%)]\tLoss: 0.136263\n",
            "Train Epoch: 14 [35200/60000 (59%)]\tLoss: 0.196812\n",
            "Train Epoch: 14 [35840/60000 (60%)]\tLoss: 0.130151\n",
            "Train Epoch: 14 [36480/60000 (61%)]\tLoss: 0.028891\n",
            "Train Epoch: 14 [37120/60000 (62%)]\tLoss: 0.086977\n",
            "Train Epoch: 14 [37760/60000 (63%)]\tLoss: 0.151976\n",
            "Train Epoch: 14 [38400/60000 (64%)]\tLoss: 0.034403\n",
            "Train Epoch: 14 [39040/60000 (65%)]\tLoss: 0.087308\n",
            "Train Epoch: 14 [39680/60000 (66%)]\tLoss: 0.165016\n",
            "Train Epoch: 14 [40320/60000 (67%)]\tLoss: 0.078043\n",
            "Train Epoch: 14 [40960/60000 (68%)]\tLoss: 0.375369\n",
            "Train Epoch: 14 [41600/60000 (69%)]\tLoss: 0.100086\n",
            "Train Epoch: 14 [42240/60000 (70%)]\tLoss: 0.129290\n",
            "Train Epoch: 14 [42880/60000 (71%)]\tLoss: 0.090253\n",
            "Train Epoch: 14 [43520/60000 (72%)]\tLoss: 0.050539\n",
            "Train Epoch: 14 [44160/60000 (74%)]\tLoss: 0.013719\n",
            "Train Epoch: 14 [44800/60000 (75%)]\tLoss: 0.078642\n",
            "Train Epoch: 14 [45440/60000 (76%)]\tLoss: 0.036310\n",
            "Train Epoch: 14 [46080/60000 (77%)]\tLoss: 0.218818\n",
            "Train Epoch: 14 [46720/60000 (78%)]\tLoss: 0.048844\n",
            "Train Epoch: 14 [47360/60000 (79%)]\tLoss: 0.099238\n",
            "Train Epoch: 14 [48000/60000 (80%)]\tLoss: 0.158102\n",
            "Train Epoch: 14 [48640/60000 (81%)]\tLoss: 0.151208\n",
            "Train Epoch: 14 [49280/60000 (82%)]\tLoss: 0.142342\n",
            "Train Epoch: 14 [49920/60000 (83%)]\tLoss: 0.147329\n",
            "Train Epoch: 14 [50560/60000 (84%)]\tLoss: 0.105276\n",
            "Train Epoch: 14 [51200/60000 (85%)]\tLoss: 0.118284\n",
            "Train Epoch: 14 [51840/60000 (86%)]\tLoss: 0.122198\n",
            "Train Epoch: 14 [52480/60000 (87%)]\tLoss: 0.154331\n",
            "Train Epoch: 14 [53120/60000 (88%)]\tLoss: 0.039742\n",
            "Train Epoch: 14 [53760/60000 (90%)]\tLoss: 0.025495\n",
            "Train Epoch: 14 [54400/60000 (91%)]\tLoss: 0.078307\n",
            "Train Epoch: 14 [55040/60000 (92%)]\tLoss: 0.099831\n",
            "Train Epoch: 14 [55680/60000 (93%)]\tLoss: 0.150818\n",
            "Train Epoch: 14 [56320/60000 (94%)]\tLoss: 0.128141\n",
            "Train Epoch: 14 [56960/60000 (95%)]\tLoss: 0.098659\n",
            "Train Epoch: 14 [57600/60000 (96%)]\tLoss: 0.085700\n",
            "Train Epoch: 14 [58240/60000 (97%)]\tLoss: 0.036696\n",
            "Train Epoch: 14 [58880/60000 (98%)]\tLoss: 0.055240\n",
            "Train Epoch: 14 [59520/60000 (99%)]\tLoss: 0.201680\n",
            "\n",
            "Test set: Average loss: 0.0496, Accuracy: 9837/10000 (98%)\n",
            "\n",
            "Train Epoch: 14 [0/60000 (0%)]\tLoss: 0.094074\n",
            "Train Epoch: 14 [640/60000 (1%)]\tLoss: 0.055132\n",
            "Train Epoch: 14 [1280/60000 (2%)]\tLoss: 0.021268\n",
            "Train Epoch: 14 [1920/60000 (3%)]\tLoss: 0.062272\n",
            "Train Epoch: 14 [2560/60000 (4%)]\tLoss: 0.021795\n",
            "Train Epoch: 14 [3200/60000 (5%)]\tLoss: 0.006534\n",
            "Train Epoch: 14 [3840/60000 (6%)]\tLoss: 0.134686\n",
            "Train Epoch: 14 [4480/60000 (7%)]\tLoss: 0.080599\n",
            "Train Epoch: 14 [5120/60000 (9%)]\tLoss: 0.139006\n",
            "Train Epoch: 14 [5760/60000 (10%)]\tLoss: 0.039324\n",
            "Train Epoch: 14 [6400/60000 (11%)]\tLoss: 0.018583\n",
            "Train Epoch: 14 [7040/60000 (12%)]\tLoss: 0.051340\n",
            "Train Epoch: 14 [7680/60000 (13%)]\tLoss: 0.166974\n",
            "Train Epoch: 14 [8320/60000 (14%)]\tLoss: 0.024412\n",
            "Train Epoch: 14 [8960/60000 (15%)]\tLoss: 0.114147\n",
            "Train Epoch: 14 [9600/60000 (16%)]\tLoss: 0.056288\n",
            "Train Epoch: 14 [10240/60000 (17%)]\tLoss: 0.046055\n",
            "Train Epoch: 14 [10880/60000 (18%)]\tLoss: 0.041693\n",
            "Train Epoch: 14 [11520/60000 (19%)]\tLoss: 0.260301\n",
            "Train Epoch: 14 [12160/60000 (20%)]\tLoss: 0.020741\n",
            "Train Epoch: 14 [12800/60000 (21%)]\tLoss: 0.006475\n",
            "Train Epoch: 14 [13440/60000 (22%)]\tLoss: 0.041801\n",
            "Train Epoch: 14 [14080/60000 (23%)]\tLoss: 0.041992\n",
            "Train Epoch: 14 [14720/60000 (25%)]\tLoss: 0.191718\n",
            "Train Epoch: 14 [15360/60000 (26%)]\tLoss: 0.117587\n",
            "Train Epoch: 14 [16000/60000 (27%)]\tLoss: 0.066985\n",
            "Train Epoch: 14 [16640/60000 (28%)]\tLoss: 0.057856\n",
            "Train Epoch: 14 [17280/60000 (29%)]\tLoss: 0.055052\n",
            "Train Epoch: 14 [17920/60000 (30%)]\tLoss: 0.050033\n",
            "Train Epoch: 14 [18560/60000 (31%)]\tLoss: 0.142669\n",
            "Train Epoch: 14 [19200/60000 (32%)]\tLoss: 0.042022\n",
            "Train Epoch: 14 [19840/60000 (33%)]\tLoss: 0.048583\n",
            "Train Epoch: 14 [20480/60000 (34%)]\tLoss: 0.060401\n",
            "Train Epoch: 14 [21120/60000 (35%)]\tLoss: 0.025441\n",
            "Train Epoch: 14 [21760/60000 (36%)]\tLoss: 0.067480\n",
            "Train Epoch: 14 [22400/60000 (37%)]\tLoss: 0.235759\n",
            "Train Epoch: 14 [23040/60000 (38%)]\tLoss: 0.011270\n",
            "Train Epoch: 14 [23680/60000 (39%)]\tLoss: 0.026411\n",
            "Train Epoch: 14 [24320/60000 (41%)]\tLoss: 0.027535\n",
            "Train Epoch: 14 [24960/60000 (42%)]\tLoss: 0.066443\n",
            "Train Epoch: 14 [25600/60000 (43%)]\tLoss: 0.020926\n",
            "Train Epoch: 14 [26240/60000 (44%)]\tLoss: 0.020602\n",
            "Train Epoch: 14 [26880/60000 (45%)]\tLoss: 0.045949\n",
            "Train Epoch: 14 [27520/60000 (46%)]\tLoss: 0.185277\n",
            "Train Epoch: 14 [28160/60000 (47%)]\tLoss: 0.058462\n",
            "Train Epoch: 14 [28800/60000 (48%)]\tLoss: 0.119014\n",
            "Train Epoch: 14 [29440/60000 (49%)]\tLoss: 0.148874\n",
            "Train Epoch: 14 [30080/60000 (50%)]\tLoss: 0.075179\n",
            "Train Epoch: 14 [30720/60000 (51%)]\tLoss: 0.058190\n",
            "Train Epoch: 14 [31360/60000 (52%)]\tLoss: 0.011472\n",
            "Train Epoch: 14 [32000/60000 (53%)]\tLoss: 0.142779\n",
            "Train Epoch: 14 [32640/60000 (54%)]\tLoss: 0.168902\n",
            "Train Epoch: 14 [33280/60000 (55%)]\tLoss: 0.151969\n",
            "Train Epoch: 14 [33920/60000 (57%)]\tLoss: 0.016497\n",
            "Train Epoch: 14 [34560/60000 (58%)]\tLoss: 0.073516\n",
            "Train Epoch: 14 [35200/60000 (59%)]\tLoss: 0.164507\n",
            "Train Epoch: 14 [35840/60000 (60%)]\tLoss: 0.014609\n",
            "Train Epoch: 14 [36480/60000 (61%)]\tLoss: 0.160102\n",
            "Train Epoch: 14 [37120/60000 (62%)]\tLoss: 0.012878\n",
            "Train Epoch: 14 [37760/60000 (63%)]\tLoss: 0.078330\n",
            "Train Epoch: 14 [38400/60000 (64%)]\tLoss: 0.039065\n",
            "Train Epoch: 14 [39040/60000 (65%)]\tLoss: 0.047089\n",
            "Train Epoch: 14 [39680/60000 (66%)]\tLoss: 0.059785\n",
            "Train Epoch: 14 [40320/60000 (67%)]\tLoss: 0.023806\n",
            "Train Epoch: 14 [40960/60000 (68%)]\tLoss: 0.040636\n",
            "Train Epoch: 14 [41600/60000 (69%)]\tLoss: 0.035040\n",
            "Train Epoch: 14 [42240/60000 (70%)]\tLoss: 0.059411\n",
            "Train Epoch: 14 [42880/60000 (71%)]\tLoss: 0.126099\n",
            "Train Epoch: 14 [43520/60000 (72%)]\tLoss: 0.107428\n",
            "Train Epoch: 14 [44160/60000 (74%)]\tLoss: 0.137774\n",
            "Train Epoch: 14 [44800/60000 (75%)]\tLoss: 0.010846\n",
            "Train Epoch: 14 [45440/60000 (76%)]\tLoss: 0.026864\n",
            "Train Epoch: 14 [46080/60000 (77%)]\tLoss: 0.020929\n",
            "Train Epoch: 14 [46720/60000 (78%)]\tLoss: 0.064176\n",
            "Train Epoch: 14 [47360/60000 (79%)]\tLoss: 0.021342\n",
            "Train Epoch: 14 [48000/60000 (80%)]\tLoss: 0.029529\n",
            "Train Epoch: 14 [48640/60000 (81%)]\tLoss: 0.147477\n",
            "Train Epoch: 14 [49280/60000 (82%)]\tLoss: 0.004990\n",
            "Train Epoch: 14 [49920/60000 (83%)]\tLoss: 0.094329\n",
            "Train Epoch: 14 [50560/60000 (84%)]\tLoss: 0.022905\n",
            "Train Epoch: 14 [51200/60000 (85%)]\tLoss: 0.036754\n",
            "Train Epoch: 14 [51840/60000 (86%)]\tLoss: 0.242224\n",
            "Train Epoch: 14 [52480/60000 (87%)]\tLoss: 0.026054\n",
            "Train Epoch: 14 [53120/60000 (88%)]\tLoss: 0.063123\n",
            "Train Epoch: 14 [53760/60000 (90%)]\tLoss: 0.012987\n",
            "Train Epoch: 14 [54400/60000 (91%)]\tLoss: 0.025014\n",
            "Train Epoch: 14 [55040/60000 (92%)]\tLoss: 0.059650\n",
            "Train Epoch: 14 [55680/60000 (93%)]\tLoss: 0.020873\n",
            "Train Epoch: 14 [56320/60000 (94%)]\tLoss: 0.087088\n",
            "Train Epoch: 14 [56960/60000 (95%)]\tLoss: 0.010604\n",
            "Train Epoch: 14 [57600/60000 (96%)]\tLoss: 0.011089\n",
            "Train Epoch: 14 [58240/60000 (97%)]\tLoss: 0.185759\n",
            "Train Epoch: 14 [58880/60000 (98%)]\tLoss: 0.019959\n",
            "Train Epoch: 14 [59520/60000 (99%)]\tLoss: 0.013128\n",
            "\n",
            "Test set: Average loss: 0.0399, Accuracy: 9872/10000 (99%)\n",
            "\n",
            "Train Epoch: 14 [0/60000 (0%)]\tLoss: 0.115087\n",
            "Train Epoch: 14 [640/60000 (1%)]\tLoss: 0.016829\n",
            "Train Epoch: 14 [1280/60000 (2%)]\tLoss: 0.078881\n",
            "Train Epoch: 14 [1920/60000 (3%)]\tLoss: 0.045204\n",
            "Train Epoch: 14 [2560/60000 (4%)]\tLoss: 0.039505\n",
            "Train Epoch: 14 [3200/60000 (5%)]\tLoss: 0.011993\n",
            "Train Epoch: 14 [3840/60000 (6%)]\tLoss: 0.037973\n",
            "Train Epoch: 14 [4480/60000 (7%)]\tLoss: 0.004987\n",
            "Train Epoch: 14 [5120/60000 (9%)]\tLoss: 0.050775\n",
            "Train Epoch: 14 [5760/60000 (10%)]\tLoss: 0.037051\n",
            "Train Epoch: 14 [6400/60000 (11%)]\tLoss: 0.094378\n",
            "Train Epoch: 14 [7040/60000 (12%)]\tLoss: 0.015076\n",
            "Train Epoch: 14 [7680/60000 (13%)]\tLoss: 0.064107\n",
            "Train Epoch: 14 [8320/60000 (14%)]\tLoss: 0.034864\n",
            "Train Epoch: 14 [8960/60000 (15%)]\tLoss: 0.027210\n",
            "Train Epoch: 14 [9600/60000 (16%)]\tLoss: 0.020175\n",
            "Train Epoch: 14 [10240/60000 (17%)]\tLoss: 0.030399\n",
            "Train Epoch: 14 [10880/60000 (18%)]\tLoss: 0.016080\n",
            "Train Epoch: 14 [11520/60000 (19%)]\tLoss: 0.037754\n",
            "Train Epoch: 14 [12160/60000 (20%)]\tLoss: 0.030100\n",
            "Train Epoch: 14 [12800/60000 (21%)]\tLoss: 0.021751\n",
            "Train Epoch: 14 [13440/60000 (22%)]\tLoss: 0.009028\n",
            "Train Epoch: 14 [14080/60000 (23%)]\tLoss: 0.102582\n",
            "Train Epoch: 14 [14720/60000 (25%)]\tLoss: 0.090958\n",
            "Train Epoch: 14 [15360/60000 (26%)]\tLoss: 0.279578\n",
            "Train Epoch: 14 [16000/60000 (27%)]\tLoss: 0.018843\n",
            "Train Epoch: 14 [16640/60000 (28%)]\tLoss: 0.028160\n",
            "Train Epoch: 14 [17280/60000 (29%)]\tLoss: 0.018924\n",
            "Train Epoch: 14 [17920/60000 (30%)]\tLoss: 0.012270\n",
            "Train Epoch: 14 [18560/60000 (31%)]\tLoss: 0.004993\n",
            "Train Epoch: 14 [19200/60000 (32%)]\tLoss: 0.050938\n",
            "Train Epoch: 14 [19840/60000 (33%)]\tLoss: 0.013863\n",
            "Train Epoch: 14 [20480/60000 (34%)]\tLoss: 0.067160\n",
            "Train Epoch: 14 [21120/60000 (35%)]\tLoss: 0.057410\n",
            "Train Epoch: 14 [21760/60000 (36%)]\tLoss: 0.038681\n",
            "Train Epoch: 14 [22400/60000 (37%)]\tLoss: 0.012014\n",
            "Train Epoch: 14 [23040/60000 (38%)]\tLoss: 0.108057\n",
            "Train Epoch: 14 [23680/60000 (39%)]\tLoss: 0.049036\n",
            "Train Epoch: 14 [24320/60000 (41%)]\tLoss: 0.064216\n",
            "Train Epoch: 14 [24960/60000 (42%)]\tLoss: 0.125393\n",
            "Train Epoch: 14 [25600/60000 (43%)]\tLoss: 0.006953\n",
            "Train Epoch: 14 [26240/60000 (44%)]\tLoss: 0.101377\n",
            "Train Epoch: 14 [26880/60000 (45%)]\tLoss: 0.011231\n",
            "Train Epoch: 14 [27520/60000 (46%)]\tLoss: 0.105270\n",
            "Train Epoch: 14 [28160/60000 (47%)]\tLoss: 0.021662\n",
            "Train Epoch: 14 [28800/60000 (48%)]\tLoss: 0.037771\n",
            "Train Epoch: 14 [29440/60000 (49%)]\tLoss: 0.030901\n",
            "Train Epoch: 14 [30080/60000 (50%)]\tLoss: 0.038957\n",
            "Train Epoch: 14 [30720/60000 (51%)]\tLoss: 0.088195\n",
            "Train Epoch: 14 [31360/60000 (52%)]\tLoss: 0.009889\n",
            "Train Epoch: 14 [32000/60000 (53%)]\tLoss: 0.131516\n",
            "Train Epoch: 14 [32640/60000 (54%)]\tLoss: 0.023210\n",
            "Train Epoch: 14 [33280/60000 (55%)]\tLoss: 0.152919\n",
            "Train Epoch: 14 [33920/60000 (57%)]\tLoss: 0.099149\n",
            "Train Epoch: 14 [34560/60000 (58%)]\tLoss: 0.055960\n",
            "Train Epoch: 14 [35200/60000 (59%)]\tLoss: 0.039703\n",
            "Train Epoch: 14 [35840/60000 (60%)]\tLoss: 0.195289\n",
            "Train Epoch: 14 [36480/60000 (61%)]\tLoss: 0.012887\n",
            "Train Epoch: 14 [37120/60000 (62%)]\tLoss: 0.030234\n",
            "Train Epoch: 14 [37760/60000 (63%)]\tLoss: 0.015043\n",
            "Train Epoch: 14 [38400/60000 (64%)]\tLoss: 0.038781\n",
            "Train Epoch: 14 [39040/60000 (65%)]\tLoss: 0.052348\n",
            "Train Epoch: 14 [39680/60000 (66%)]\tLoss: 0.023032\n",
            "Train Epoch: 14 [40320/60000 (67%)]\tLoss: 0.041703\n",
            "Train Epoch: 14 [40960/60000 (68%)]\tLoss: 0.032481\n",
            "Train Epoch: 14 [41600/60000 (69%)]\tLoss: 0.018097\n",
            "Train Epoch: 14 [42240/60000 (70%)]\tLoss: 0.044529\n",
            "Train Epoch: 14 [42880/60000 (71%)]\tLoss: 0.013744\n",
            "Train Epoch: 14 [43520/60000 (72%)]\tLoss: 0.078984\n",
            "Train Epoch: 14 [44160/60000 (74%)]\tLoss: 0.186290\n",
            "Train Epoch: 14 [44800/60000 (75%)]\tLoss: 0.114394\n",
            "Train Epoch: 14 [45440/60000 (76%)]\tLoss: 0.013018\n",
            "Train Epoch: 14 [46080/60000 (77%)]\tLoss: 0.075417\n",
            "Train Epoch: 14 [46720/60000 (78%)]\tLoss: 0.012250\n",
            "Train Epoch: 14 [47360/60000 (79%)]\tLoss: 0.146537\n",
            "Train Epoch: 14 [48000/60000 (80%)]\tLoss: 0.046803\n",
            "Train Epoch: 14 [48640/60000 (81%)]\tLoss: 0.051657\n",
            "Train Epoch: 14 [49280/60000 (82%)]\tLoss: 0.064391\n",
            "Train Epoch: 14 [49920/60000 (83%)]\tLoss: 0.017026\n",
            "Train Epoch: 14 [50560/60000 (84%)]\tLoss: 0.027501\n",
            "Train Epoch: 14 [51200/60000 (85%)]\tLoss: 0.020977\n",
            "Train Epoch: 14 [51840/60000 (86%)]\tLoss: 0.212123\n",
            "Train Epoch: 14 [52480/60000 (87%)]\tLoss: 0.003761\n",
            "Train Epoch: 14 [53120/60000 (88%)]\tLoss: 0.030450\n",
            "Train Epoch: 14 [53760/60000 (90%)]\tLoss: 0.090609\n",
            "Train Epoch: 14 [54400/60000 (91%)]\tLoss: 0.029863\n",
            "Train Epoch: 14 [55040/60000 (92%)]\tLoss: 0.122259\n",
            "Train Epoch: 14 [55680/60000 (93%)]\tLoss: 0.179570\n",
            "Train Epoch: 14 [56320/60000 (94%)]\tLoss: 0.211605\n",
            "Train Epoch: 14 [56960/60000 (95%)]\tLoss: 0.025597\n",
            "Train Epoch: 14 [57600/60000 (96%)]\tLoss: 0.005658\n",
            "Train Epoch: 14 [58240/60000 (97%)]\tLoss: 0.010298\n",
            "Train Epoch: 14 [58880/60000 (98%)]\tLoss: 0.010506\n",
            "Train Epoch: 14 [59520/60000 (99%)]\tLoss: 0.002055\n",
            "\n",
            "Test set: Average loss: 0.0327, Accuracy: 9888/10000 (99%)\n",
            "\n",
            "Train Epoch: 14 [0/60000 (0%)]\tLoss: 0.006009\n",
            "Train Epoch: 14 [640/60000 (1%)]\tLoss: 0.006882\n",
            "Train Epoch: 14 [1280/60000 (2%)]\tLoss: 0.067614\n",
            "Train Epoch: 14 [1920/60000 (3%)]\tLoss: 0.011643\n",
            "Train Epoch: 14 [2560/60000 (4%)]\tLoss: 0.046631\n",
            "Train Epoch: 14 [3200/60000 (5%)]\tLoss: 0.033517\n",
            "Train Epoch: 14 [3840/60000 (6%)]\tLoss: 0.006841\n",
            "Train Epoch: 14 [4480/60000 (7%)]\tLoss: 0.095453\n",
            "Train Epoch: 14 [5120/60000 (9%)]\tLoss: 0.060731\n",
            "Train Epoch: 14 [5760/60000 (10%)]\tLoss: 0.093180\n",
            "Train Epoch: 14 [6400/60000 (11%)]\tLoss: 0.060416\n",
            "Train Epoch: 14 [7040/60000 (12%)]\tLoss: 0.014153\n",
            "Train Epoch: 14 [7680/60000 (13%)]\tLoss: 0.084950\n",
            "Train Epoch: 14 [8320/60000 (14%)]\tLoss: 0.008767\n",
            "Train Epoch: 14 [8960/60000 (15%)]\tLoss: 0.034877\n",
            "Train Epoch: 14 [9600/60000 (16%)]\tLoss: 0.184502\n",
            "Train Epoch: 14 [10240/60000 (17%)]\tLoss: 0.009898\n",
            "Train Epoch: 14 [10880/60000 (18%)]\tLoss: 0.057535\n",
            "Train Epoch: 14 [11520/60000 (19%)]\tLoss: 0.023989\n",
            "Train Epoch: 14 [12160/60000 (20%)]\tLoss: 0.011162\n",
            "Train Epoch: 14 [12800/60000 (21%)]\tLoss: 0.015460\n",
            "Train Epoch: 14 [13440/60000 (22%)]\tLoss: 0.007794\n",
            "Train Epoch: 14 [14080/60000 (23%)]\tLoss: 0.084830\n",
            "Train Epoch: 14 [14720/60000 (25%)]\tLoss: 0.015900\n",
            "Train Epoch: 14 [15360/60000 (26%)]\tLoss: 0.017926\n",
            "Train Epoch: 14 [16000/60000 (27%)]\tLoss: 0.039469\n",
            "Train Epoch: 14 [16640/60000 (28%)]\tLoss: 0.013167\n",
            "Train Epoch: 14 [17280/60000 (29%)]\tLoss: 0.027456\n",
            "Train Epoch: 14 [17920/60000 (30%)]\tLoss: 0.029028\n",
            "Train Epoch: 14 [18560/60000 (31%)]\tLoss: 0.016127\n",
            "Train Epoch: 14 [19200/60000 (32%)]\tLoss: 0.223001\n",
            "Train Epoch: 14 [19840/60000 (33%)]\tLoss: 0.063911\n",
            "Train Epoch: 14 [20480/60000 (34%)]\tLoss: 0.010678\n",
            "Train Epoch: 14 [21120/60000 (35%)]\tLoss: 0.079539\n",
            "Train Epoch: 14 [21760/60000 (36%)]\tLoss: 0.039507\n",
            "Train Epoch: 14 [22400/60000 (37%)]\tLoss: 0.007274\n",
            "Train Epoch: 14 [23040/60000 (38%)]\tLoss: 0.101688\n",
            "Train Epoch: 14 [23680/60000 (39%)]\tLoss: 0.021030\n",
            "Train Epoch: 14 [24320/60000 (41%)]\tLoss: 0.026608\n",
            "Train Epoch: 14 [24960/60000 (42%)]\tLoss: 0.028725\n",
            "Train Epoch: 14 [25600/60000 (43%)]\tLoss: 0.023314\n",
            "Train Epoch: 14 [26240/60000 (44%)]\tLoss: 0.073983\n",
            "Train Epoch: 14 [26880/60000 (45%)]\tLoss: 0.007263\n",
            "Train Epoch: 14 [27520/60000 (46%)]\tLoss: 0.015070\n",
            "Train Epoch: 14 [28160/60000 (47%)]\tLoss: 0.070029\n",
            "Train Epoch: 14 [28800/60000 (48%)]\tLoss: 0.055417\n",
            "Train Epoch: 14 [29440/60000 (49%)]\tLoss: 0.045827\n",
            "Train Epoch: 14 [30080/60000 (50%)]\tLoss: 0.024903\n",
            "Train Epoch: 14 [30720/60000 (51%)]\tLoss: 0.103565\n",
            "Train Epoch: 14 [31360/60000 (52%)]\tLoss: 0.008454\n",
            "Train Epoch: 14 [32000/60000 (53%)]\tLoss: 0.019621\n",
            "Train Epoch: 14 [32640/60000 (54%)]\tLoss: 0.014917\n",
            "Train Epoch: 14 [33280/60000 (55%)]\tLoss: 0.040022\n",
            "Train Epoch: 14 [33920/60000 (57%)]\tLoss: 0.069757\n",
            "Train Epoch: 14 [34560/60000 (58%)]\tLoss: 0.017761\n",
            "Train Epoch: 14 [35200/60000 (59%)]\tLoss: 0.004231\n",
            "Train Epoch: 14 [35840/60000 (60%)]\tLoss: 0.042105\n",
            "Train Epoch: 14 [36480/60000 (61%)]\tLoss: 0.126258\n",
            "Train Epoch: 14 [37120/60000 (62%)]\tLoss: 0.009311\n",
            "Train Epoch: 14 [37760/60000 (63%)]\tLoss: 0.023922\n",
            "Train Epoch: 14 [38400/60000 (64%)]\tLoss: 0.148835\n",
            "Train Epoch: 14 [39040/60000 (65%)]\tLoss: 0.119721\n",
            "Train Epoch: 14 [39680/60000 (66%)]\tLoss: 0.020238\n",
            "Train Epoch: 14 [40320/60000 (67%)]\tLoss: 0.018006\n",
            "Train Epoch: 14 [40960/60000 (68%)]\tLoss: 0.020831\n",
            "Train Epoch: 14 [41600/60000 (69%)]\tLoss: 0.191756\n",
            "Train Epoch: 14 [42240/60000 (70%)]\tLoss: 0.029064\n",
            "Train Epoch: 14 [42880/60000 (71%)]\tLoss: 0.016716\n",
            "Train Epoch: 14 [43520/60000 (72%)]\tLoss: 0.131706\n",
            "Train Epoch: 14 [44160/60000 (74%)]\tLoss: 0.046866\n",
            "Train Epoch: 14 [44800/60000 (75%)]\tLoss: 0.018415\n",
            "Train Epoch: 14 [45440/60000 (76%)]\tLoss: 0.093109\n",
            "Train Epoch: 14 [46080/60000 (77%)]\tLoss: 0.006285\n",
            "Train Epoch: 14 [46720/60000 (78%)]\tLoss: 0.141301\n",
            "Train Epoch: 14 [47360/60000 (79%)]\tLoss: 0.126067\n",
            "Train Epoch: 14 [48000/60000 (80%)]\tLoss: 0.098551\n",
            "Train Epoch: 14 [48640/60000 (81%)]\tLoss: 0.098311\n",
            "Train Epoch: 14 [49280/60000 (82%)]\tLoss: 0.009072\n",
            "Train Epoch: 14 [49920/60000 (83%)]\tLoss: 0.035582\n",
            "Train Epoch: 14 [50560/60000 (84%)]\tLoss: 0.137975\n",
            "Train Epoch: 14 [51200/60000 (85%)]\tLoss: 0.120011\n",
            "Train Epoch: 14 [51840/60000 (86%)]\tLoss: 0.085378\n",
            "Train Epoch: 14 [52480/60000 (87%)]\tLoss: 0.027159\n",
            "Train Epoch: 14 [53120/60000 (88%)]\tLoss: 0.016723\n",
            "Train Epoch: 14 [53760/60000 (90%)]\tLoss: 0.039502\n",
            "Train Epoch: 14 [54400/60000 (91%)]\tLoss: 0.010165\n",
            "Train Epoch: 14 [55040/60000 (92%)]\tLoss: 0.012437\n",
            "Train Epoch: 14 [55680/60000 (93%)]\tLoss: 0.006127\n",
            "Train Epoch: 14 [56320/60000 (94%)]\tLoss: 0.033419\n",
            "Train Epoch: 14 [56960/60000 (95%)]\tLoss: 0.003380\n",
            "Train Epoch: 14 [57600/60000 (96%)]\tLoss: 0.003147\n",
            "Train Epoch: 14 [58240/60000 (97%)]\tLoss: 0.104361\n",
            "Train Epoch: 14 [58880/60000 (98%)]\tLoss: 0.007964\n",
            "Train Epoch: 14 [59520/60000 (99%)]\tLoss: 0.000409\n",
            "\n",
            "Test set: Average loss: 0.0319, Accuracy: 9893/10000 (99%)\n",
            "\n",
            "Train Epoch: 14 [0/60000 (0%)]\tLoss: 0.032626\n",
            "Train Epoch: 14 [640/60000 (1%)]\tLoss: 0.039283\n",
            "Train Epoch: 14 [1280/60000 (2%)]\tLoss: 0.071170\n",
            "Train Epoch: 14 [1920/60000 (3%)]\tLoss: 0.026017\n",
            "Train Epoch: 14 [2560/60000 (4%)]\tLoss: 0.070465\n",
            "Train Epoch: 14 [3200/60000 (5%)]\tLoss: 0.022439\n",
            "Train Epoch: 14 [3840/60000 (6%)]\tLoss: 0.004124\n",
            "Train Epoch: 14 [4480/60000 (7%)]\tLoss: 0.031719\n",
            "Train Epoch: 14 [5120/60000 (9%)]\tLoss: 0.060064\n",
            "Train Epoch: 14 [5760/60000 (10%)]\tLoss: 0.041736\n",
            "Train Epoch: 14 [6400/60000 (11%)]\tLoss: 0.207030\n",
            "Train Epoch: 14 [7040/60000 (12%)]\tLoss: 0.018631\n",
            "Train Epoch: 14 [7680/60000 (13%)]\tLoss: 0.070944\n",
            "Train Epoch: 14 [8320/60000 (14%)]\tLoss: 0.110012\n",
            "Train Epoch: 14 [8960/60000 (15%)]\tLoss: 0.014323\n",
            "Train Epoch: 14 [9600/60000 (16%)]\tLoss: 0.023052\n",
            "Train Epoch: 14 [10240/60000 (17%)]\tLoss: 0.071742\n",
            "Train Epoch: 14 [10880/60000 (18%)]\tLoss: 0.042303\n",
            "Train Epoch: 14 [11520/60000 (19%)]\tLoss: 0.005979\n",
            "Train Epoch: 14 [12160/60000 (20%)]\tLoss: 0.039354\n",
            "Train Epoch: 14 [12800/60000 (21%)]\tLoss: 0.009727\n",
            "Train Epoch: 14 [13440/60000 (22%)]\tLoss: 0.083344\n",
            "Train Epoch: 14 [14080/60000 (23%)]\tLoss: 0.012471\n",
            "Train Epoch: 14 [14720/60000 (25%)]\tLoss: 0.021669\n",
            "Train Epoch: 14 [15360/60000 (26%)]\tLoss: 0.009040\n",
            "Train Epoch: 14 [16000/60000 (27%)]\tLoss: 0.022363\n",
            "Train Epoch: 14 [16640/60000 (28%)]\tLoss: 0.078045\n",
            "Train Epoch: 14 [17280/60000 (29%)]\tLoss: 0.041732\n",
            "Train Epoch: 14 [17920/60000 (30%)]\tLoss: 0.048823\n",
            "Train Epoch: 14 [18560/60000 (31%)]\tLoss: 0.052770\n",
            "Train Epoch: 14 [19200/60000 (32%)]\tLoss: 0.049280\n",
            "Train Epoch: 14 [19840/60000 (33%)]\tLoss: 0.092714\n",
            "Train Epoch: 14 [20480/60000 (34%)]\tLoss: 0.039257\n",
            "Train Epoch: 14 [21120/60000 (35%)]\tLoss: 0.028921\n",
            "Train Epoch: 14 [21760/60000 (36%)]\tLoss: 0.076775\n",
            "Train Epoch: 14 [22400/60000 (37%)]\tLoss: 0.087931\n",
            "Train Epoch: 14 [23040/60000 (38%)]\tLoss: 0.001618\n",
            "Train Epoch: 14 [23680/60000 (39%)]\tLoss: 0.008200\n",
            "Train Epoch: 14 [24320/60000 (41%)]\tLoss: 0.013030\n",
            "Train Epoch: 14 [24960/60000 (42%)]\tLoss: 0.079366\n",
            "Train Epoch: 14 [25600/60000 (43%)]\tLoss: 0.008710\n",
            "Train Epoch: 14 [26240/60000 (44%)]\tLoss: 0.062669\n",
            "Train Epoch: 14 [26880/60000 (45%)]\tLoss: 0.118044\n",
            "Train Epoch: 14 [27520/60000 (46%)]\tLoss: 0.007822\n",
            "Train Epoch: 14 [28160/60000 (47%)]\tLoss: 0.189889\n",
            "Train Epoch: 14 [28800/60000 (48%)]\tLoss: 0.012782\n",
            "Train Epoch: 14 [29440/60000 (49%)]\tLoss: 0.036480\n",
            "Train Epoch: 14 [30080/60000 (50%)]\tLoss: 0.039334\n",
            "Train Epoch: 14 [30720/60000 (51%)]\tLoss: 0.045428\n",
            "Train Epoch: 14 [31360/60000 (52%)]\tLoss: 0.004410\n",
            "Train Epoch: 14 [32000/60000 (53%)]\tLoss: 0.044738\n",
            "Train Epoch: 14 [32640/60000 (54%)]\tLoss: 0.027956\n",
            "Train Epoch: 14 [33280/60000 (55%)]\tLoss: 0.017326\n",
            "Train Epoch: 14 [33920/60000 (57%)]\tLoss: 0.023541\n",
            "Train Epoch: 14 [34560/60000 (58%)]\tLoss: 0.003107\n",
            "Train Epoch: 14 [35200/60000 (59%)]\tLoss: 0.031496\n",
            "Train Epoch: 14 [35840/60000 (60%)]\tLoss: 0.117472\n",
            "Train Epoch: 14 [36480/60000 (61%)]\tLoss: 0.016666\n",
            "Train Epoch: 14 [37120/60000 (62%)]\tLoss: 0.010041\n",
            "Train Epoch: 14 [37760/60000 (63%)]\tLoss: 0.013728\n",
            "Train Epoch: 14 [38400/60000 (64%)]\tLoss: 0.046365\n",
            "Train Epoch: 14 [39040/60000 (65%)]\tLoss: 0.002378\n",
            "Train Epoch: 14 [39680/60000 (66%)]\tLoss: 0.008327\n",
            "Train Epoch: 14 [40320/60000 (67%)]\tLoss: 0.009952\n",
            "Train Epoch: 14 [40960/60000 (68%)]\tLoss: 0.096818\n",
            "Train Epoch: 14 [41600/60000 (69%)]\tLoss: 0.048142\n",
            "Train Epoch: 14 [42240/60000 (70%)]\tLoss: 0.014532\n",
            "Train Epoch: 14 [42880/60000 (71%)]\tLoss: 0.016773\n",
            "Train Epoch: 14 [43520/60000 (72%)]\tLoss: 0.060381\n",
            "Train Epoch: 14 [44160/60000 (74%)]\tLoss: 0.075880\n",
            "Train Epoch: 14 [44800/60000 (75%)]\tLoss: 0.069028\n",
            "Train Epoch: 14 [45440/60000 (76%)]\tLoss: 0.024332\n",
            "Train Epoch: 14 [46080/60000 (77%)]\tLoss: 0.008859\n",
            "Train Epoch: 14 [46720/60000 (78%)]\tLoss: 0.031468\n",
            "Train Epoch: 14 [47360/60000 (79%)]\tLoss: 0.028923\n",
            "Train Epoch: 14 [48000/60000 (80%)]\tLoss: 0.082644\n",
            "Train Epoch: 14 [48640/60000 (81%)]\tLoss: 0.086494\n",
            "Train Epoch: 14 [49280/60000 (82%)]\tLoss: 0.011372\n",
            "Train Epoch: 14 [49920/60000 (83%)]\tLoss: 0.017861\n",
            "Train Epoch: 14 [50560/60000 (84%)]\tLoss: 0.012120\n",
            "Train Epoch: 14 [51200/60000 (85%)]\tLoss: 0.026497\n",
            "Train Epoch: 14 [51840/60000 (86%)]\tLoss: 0.037208\n",
            "Train Epoch: 14 [52480/60000 (87%)]\tLoss: 0.049031\n",
            "Train Epoch: 14 [53120/60000 (88%)]\tLoss: 0.018574\n",
            "Train Epoch: 14 [53760/60000 (90%)]\tLoss: 0.007915\n",
            "Train Epoch: 14 [54400/60000 (91%)]\tLoss: 0.025476\n",
            "Train Epoch: 14 [55040/60000 (92%)]\tLoss: 0.013907\n",
            "Train Epoch: 14 [55680/60000 (93%)]\tLoss: 0.003996\n",
            "Train Epoch: 14 [56320/60000 (94%)]\tLoss: 0.145132\n",
            "Train Epoch: 14 [56960/60000 (95%)]\tLoss: 0.080291\n",
            "Train Epoch: 14 [57600/60000 (96%)]\tLoss: 0.039376\n",
            "Train Epoch: 14 [58240/60000 (97%)]\tLoss: 0.048337\n",
            "Train Epoch: 14 [58880/60000 (98%)]\tLoss: 0.067556\n",
            "Train Epoch: 14 [59520/60000 (99%)]\tLoss: 0.009796\n",
            "\n",
            "Test set: Average loss: 0.0323, Accuracy: 9892/10000 (99%)\n",
            "\n",
            "Train Epoch: 14 [0/60000 (0%)]\tLoss: 0.020392\n",
            "Train Epoch: 14 [640/60000 (1%)]\tLoss: 0.059815\n",
            "Train Epoch: 14 [1280/60000 (2%)]\tLoss: 0.002249\n",
            "Train Epoch: 14 [1920/60000 (3%)]\tLoss: 0.033593\n",
            "Train Epoch: 14 [2560/60000 (4%)]\tLoss: 0.013270\n",
            "Train Epoch: 14 [3200/60000 (5%)]\tLoss: 0.001645\n",
            "Train Epoch: 14 [3840/60000 (6%)]\tLoss: 0.033042\n",
            "Train Epoch: 14 [4480/60000 (7%)]\tLoss: 0.043929\n",
            "Train Epoch: 14 [5120/60000 (9%)]\tLoss: 0.112958\n",
            "Train Epoch: 14 [5760/60000 (10%)]\tLoss: 0.019009\n",
            "Train Epoch: 14 [6400/60000 (11%)]\tLoss: 0.004597\n",
            "Train Epoch: 14 [7040/60000 (12%)]\tLoss: 0.148635\n",
            "Train Epoch: 14 [7680/60000 (13%)]\tLoss: 0.005438\n",
            "Train Epoch: 14 [8320/60000 (14%)]\tLoss: 0.090328\n",
            "Train Epoch: 14 [8960/60000 (15%)]\tLoss: 0.019768\n",
            "Train Epoch: 14 [9600/60000 (16%)]\tLoss: 0.008108\n",
            "Train Epoch: 14 [10240/60000 (17%)]\tLoss: 0.011131\n",
            "Train Epoch: 14 [10880/60000 (18%)]\tLoss: 0.015326\n",
            "Train Epoch: 14 [11520/60000 (19%)]\tLoss: 0.124285\n",
            "Train Epoch: 14 [12160/60000 (20%)]\tLoss: 0.015622\n",
            "Train Epoch: 14 [12800/60000 (21%)]\tLoss: 0.004331\n",
            "Train Epoch: 14 [13440/60000 (22%)]\tLoss: 0.071465\n",
            "Train Epoch: 14 [14080/60000 (23%)]\tLoss: 0.093156\n",
            "Train Epoch: 14 [14720/60000 (25%)]\tLoss: 0.012831\n",
            "Train Epoch: 14 [15360/60000 (26%)]\tLoss: 0.017081\n",
            "Train Epoch: 14 [16000/60000 (27%)]\tLoss: 0.003164\n",
            "Train Epoch: 14 [16640/60000 (28%)]\tLoss: 0.091949\n",
            "Train Epoch: 14 [17280/60000 (29%)]\tLoss: 0.001482\n",
            "Train Epoch: 14 [17920/60000 (30%)]\tLoss: 0.007598\n",
            "Train Epoch: 14 [18560/60000 (31%)]\tLoss: 0.063953\n",
            "Train Epoch: 14 [19200/60000 (32%)]\tLoss: 0.001584\n",
            "Train Epoch: 14 [19840/60000 (33%)]\tLoss: 0.067912\n",
            "Train Epoch: 14 [20480/60000 (34%)]\tLoss: 0.040634\n",
            "Train Epoch: 14 [21120/60000 (35%)]\tLoss: 0.017702\n",
            "Train Epoch: 14 [21760/60000 (36%)]\tLoss: 0.003063\n",
            "Train Epoch: 14 [22400/60000 (37%)]\tLoss: 0.098731\n",
            "Train Epoch: 14 [23040/60000 (38%)]\tLoss: 0.046235\n",
            "Train Epoch: 14 [23680/60000 (39%)]\tLoss: 0.017470\n",
            "Train Epoch: 14 [24320/60000 (41%)]\tLoss: 0.011728\n",
            "Train Epoch: 14 [24960/60000 (42%)]\tLoss: 0.006308\n",
            "Train Epoch: 14 [25600/60000 (43%)]\tLoss: 0.029620\n",
            "Train Epoch: 14 [26240/60000 (44%)]\tLoss: 0.055786\n",
            "Train Epoch: 14 [26880/60000 (45%)]\tLoss: 0.005935\n",
            "Train Epoch: 14 [27520/60000 (46%)]\tLoss: 0.021024\n",
            "Train Epoch: 14 [28160/60000 (47%)]\tLoss: 0.015051\n",
            "Train Epoch: 14 [28800/60000 (48%)]\tLoss: 0.036763\n",
            "Train Epoch: 14 [29440/60000 (49%)]\tLoss: 0.011653\n",
            "Train Epoch: 14 [30080/60000 (50%)]\tLoss: 0.035503\n",
            "Train Epoch: 14 [30720/60000 (51%)]\tLoss: 0.015355\n",
            "Train Epoch: 14 [31360/60000 (52%)]\tLoss: 0.016218\n",
            "Train Epoch: 14 [32000/60000 (53%)]\tLoss: 0.002256\n",
            "Train Epoch: 14 [32640/60000 (54%)]\tLoss: 0.040464\n",
            "Train Epoch: 14 [33280/60000 (55%)]\tLoss: 0.029065\n",
            "Train Epoch: 14 [33920/60000 (57%)]\tLoss: 0.023427\n",
            "Train Epoch: 14 [34560/60000 (58%)]\tLoss: 0.047439\n",
            "Train Epoch: 14 [35200/60000 (59%)]\tLoss: 0.068950\n",
            "Train Epoch: 14 [35840/60000 (60%)]\tLoss: 0.004136\n",
            "Train Epoch: 14 [36480/60000 (61%)]\tLoss: 0.056149\n",
            "Train Epoch: 14 [37120/60000 (62%)]\tLoss: 0.019865\n",
            "Train Epoch: 14 [37760/60000 (63%)]\tLoss: 0.140297\n",
            "Train Epoch: 14 [38400/60000 (64%)]\tLoss: 0.012349\n",
            "Train Epoch: 14 [39040/60000 (65%)]\tLoss: 0.016129\n",
            "Train Epoch: 14 [39680/60000 (66%)]\tLoss: 0.011722\n",
            "Train Epoch: 14 [40320/60000 (67%)]\tLoss: 0.006850\n",
            "Train Epoch: 14 [40960/60000 (68%)]\tLoss: 0.007474\n",
            "Train Epoch: 14 [41600/60000 (69%)]\tLoss: 0.014375\n",
            "Train Epoch: 14 [42240/60000 (70%)]\tLoss: 0.024878\n",
            "Train Epoch: 14 [42880/60000 (71%)]\tLoss: 0.049338\n",
            "Train Epoch: 14 [43520/60000 (72%)]\tLoss: 0.021364\n",
            "Train Epoch: 14 [44160/60000 (74%)]\tLoss: 0.017940\n",
            "Train Epoch: 14 [44800/60000 (75%)]\tLoss: 0.016924\n",
            "Train Epoch: 14 [45440/60000 (76%)]\tLoss: 0.021792\n",
            "Train Epoch: 14 [46080/60000 (77%)]\tLoss: 0.021931\n",
            "Train Epoch: 14 [46720/60000 (78%)]\tLoss: 0.023644\n",
            "Train Epoch: 14 [47360/60000 (79%)]\tLoss: 0.079159\n",
            "Train Epoch: 14 [48000/60000 (80%)]\tLoss: 0.027865\n",
            "Train Epoch: 14 [48640/60000 (81%)]\tLoss: 0.024427\n",
            "Train Epoch: 14 [49280/60000 (82%)]\tLoss: 0.058876\n",
            "Train Epoch: 14 [49920/60000 (83%)]\tLoss: 0.136697\n",
            "Train Epoch: 14 [50560/60000 (84%)]\tLoss: 0.003118\n",
            "Train Epoch: 14 [51200/60000 (85%)]\tLoss: 0.011572\n",
            "Train Epoch: 14 [51840/60000 (86%)]\tLoss: 0.054395\n",
            "Train Epoch: 14 [52480/60000 (87%)]\tLoss: 0.070725\n",
            "Train Epoch: 14 [53120/60000 (88%)]\tLoss: 0.052575\n",
            "Train Epoch: 14 [53760/60000 (90%)]\tLoss: 0.007008\n",
            "Train Epoch: 14 [54400/60000 (91%)]\tLoss: 0.052745\n",
            "Train Epoch: 14 [55040/60000 (92%)]\tLoss: 0.025528\n",
            "Train Epoch: 14 [55680/60000 (93%)]\tLoss: 0.027872\n",
            "Train Epoch: 14 [56320/60000 (94%)]\tLoss: 0.021397\n",
            "Train Epoch: 14 [56960/60000 (95%)]\tLoss: 0.023770\n",
            "Train Epoch: 14 [57600/60000 (96%)]\tLoss: 0.029567\n",
            "Train Epoch: 14 [58240/60000 (97%)]\tLoss: 0.007416\n",
            "Train Epoch: 14 [58880/60000 (98%)]\tLoss: 0.004685\n",
            "Train Epoch: 14 [59520/60000 (99%)]\tLoss: 0.029130\n",
            "\n",
            "Test set: Average loss: 0.0291, Accuracy: 9907/10000 (99%)\n",
            "\n",
            "Train Epoch: 14 [0/60000 (0%)]\tLoss: 0.058588\n",
            "Train Epoch: 14 [640/60000 (1%)]\tLoss: 0.006114\n",
            "Train Epoch: 14 [1280/60000 (2%)]\tLoss: 0.075200\n",
            "Train Epoch: 14 [1920/60000 (3%)]\tLoss: 0.033775\n",
            "Train Epoch: 14 [2560/60000 (4%)]\tLoss: 0.003342\n",
            "Train Epoch: 14 [3200/60000 (5%)]\tLoss: 0.024875\n",
            "Train Epoch: 14 [3840/60000 (6%)]\tLoss: 0.003947\n",
            "Train Epoch: 14 [4480/60000 (7%)]\tLoss: 0.025174\n",
            "Train Epoch: 14 [5120/60000 (9%)]\tLoss: 0.007410\n",
            "Train Epoch: 14 [5760/60000 (10%)]\tLoss: 0.009164\n",
            "Train Epoch: 14 [6400/60000 (11%)]\tLoss: 0.012662\n",
            "Train Epoch: 14 [7040/60000 (12%)]\tLoss: 0.039684\n",
            "Train Epoch: 14 [7680/60000 (13%)]\tLoss: 0.007496\n",
            "Train Epoch: 14 [8320/60000 (14%)]\tLoss: 0.037492\n",
            "Train Epoch: 14 [8960/60000 (15%)]\tLoss: 0.093548\n",
            "Train Epoch: 14 [9600/60000 (16%)]\tLoss: 0.023958\n",
            "Train Epoch: 14 [10240/60000 (17%)]\tLoss: 0.017081\n",
            "Train Epoch: 14 [10880/60000 (18%)]\tLoss: 0.018309\n",
            "Train Epoch: 14 [11520/60000 (19%)]\tLoss: 0.049497\n",
            "Train Epoch: 14 [12160/60000 (20%)]\tLoss: 0.006559\n",
            "Train Epoch: 14 [12800/60000 (21%)]\tLoss: 0.143828\n",
            "Train Epoch: 14 [13440/60000 (22%)]\tLoss: 0.031825\n",
            "Train Epoch: 14 [14080/60000 (23%)]\tLoss: 0.001092\n",
            "Train Epoch: 14 [14720/60000 (25%)]\tLoss: 0.001830\n",
            "Train Epoch: 14 [15360/60000 (26%)]\tLoss: 0.109794\n",
            "Train Epoch: 14 [16000/60000 (27%)]\tLoss: 0.002897\n",
            "Train Epoch: 14 [16640/60000 (28%)]\tLoss: 0.056347\n",
            "Train Epoch: 14 [17280/60000 (29%)]\tLoss: 0.054380\n",
            "Train Epoch: 14 [17920/60000 (30%)]\tLoss: 0.013540\n",
            "Train Epoch: 14 [18560/60000 (31%)]\tLoss: 0.025731\n",
            "Train Epoch: 14 [19200/60000 (32%)]\tLoss: 0.013556\n",
            "Train Epoch: 14 [19840/60000 (33%)]\tLoss: 0.001329\n",
            "Train Epoch: 14 [20480/60000 (34%)]\tLoss: 0.027214\n",
            "Train Epoch: 14 [21120/60000 (35%)]\tLoss: 0.013654\n",
            "Train Epoch: 14 [21760/60000 (36%)]\tLoss: 0.001528\n",
            "Train Epoch: 14 [22400/60000 (37%)]\tLoss: 0.002467\n",
            "Train Epoch: 14 [23040/60000 (38%)]\tLoss: 0.002998\n",
            "Train Epoch: 14 [23680/60000 (39%)]\tLoss: 0.014809\n",
            "Train Epoch: 14 [24320/60000 (41%)]\tLoss: 0.012966\n",
            "Train Epoch: 14 [24960/60000 (42%)]\tLoss: 0.004707\n",
            "Train Epoch: 14 [25600/60000 (43%)]\tLoss: 0.062831\n",
            "Train Epoch: 14 [26240/60000 (44%)]\tLoss: 0.028641\n",
            "Train Epoch: 14 [26880/60000 (45%)]\tLoss: 0.001923\n",
            "Train Epoch: 14 [27520/60000 (46%)]\tLoss: 0.017522\n",
            "Train Epoch: 14 [28160/60000 (47%)]\tLoss: 0.006259\n",
            "Train Epoch: 14 [28800/60000 (48%)]\tLoss: 0.077243\n",
            "Train Epoch: 14 [29440/60000 (49%)]\tLoss: 0.002521\n",
            "Train Epoch: 14 [30080/60000 (50%)]\tLoss: 0.028360\n",
            "Train Epoch: 14 [30720/60000 (51%)]\tLoss: 0.043710\n",
            "Train Epoch: 14 [31360/60000 (52%)]\tLoss: 0.068908\n",
            "Train Epoch: 14 [32000/60000 (53%)]\tLoss: 0.043525\n",
            "Train Epoch: 14 [32640/60000 (54%)]\tLoss: 0.025282\n",
            "Train Epoch: 14 [33280/60000 (55%)]\tLoss: 0.034762\n",
            "Train Epoch: 14 [33920/60000 (57%)]\tLoss: 0.035262\n",
            "Train Epoch: 14 [34560/60000 (58%)]\tLoss: 0.016433\n",
            "Train Epoch: 14 [35200/60000 (59%)]\tLoss: 0.000518\n",
            "Train Epoch: 14 [35840/60000 (60%)]\tLoss: 0.001105\n",
            "Train Epoch: 14 [36480/60000 (61%)]\tLoss: 0.003250\n",
            "Train Epoch: 14 [37120/60000 (62%)]\tLoss: 0.022253\n",
            "Train Epoch: 14 [37760/60000 (63%)]\tLoss: 0.104216\n",
            "Train Epoch: 14 [38400/60000 (64%)]\tLoss: 0.003042\n",
            "Train Epoch: 14 [39040/60000 (65%)]\tLoss: 0.001809\n",
            "Train Epoch: 14 [39680/60000 (66%)]\tLoss: 0.005509\n",
            "Train Epoch: 14 [40320/60000 (67%)]\tLoss: 0.061857\n",
            "Train Epoch: 14 [40960/60000 (68%)]\tLoss: 0.030163\n",
            "Train Epoch: 14 [41600/60000 (69%)]\tLoss: 0.344177\n",
            "Train Epoch: 14 [42240/60000 (70%)]\tLoss: 0.003603\n",
            "Train Epoch: 14 [42880/60000 (71%)]\tLoss: 0.005938\n",
            "Train Epoch: 14 [43520/60000 (72%)]\tLoss: 0.018233\n",
            "Train Epoch: 14 [44160/60000 (74%)]\tLoss: 0.015382\n",
            "Train Epoch: 14 [44800/60000 (75%)]\tLoss: 0.032953\n",
            "Train Epoch: 14 [45440/60000 (76%)]\tLoss: 0.030510\n",
            "Train Epoch: 14 [46080/60000 (77%)]\tLoss: 0.025157\n",
            "Train Epoch: 14 [46720/60000 (78%)]\tLoss: 0.004014\n",
            "Train Epoch: 14 [47360/60000 (79%)]\tLoss: 0.005077\n",
            "Train Epoch: 14 [48000/60000 (80%)]\tLoss: 0.065864\n",
            "Train Epoch: 14 [48640/60000 (81%)]\tLoss: 0.026273\n",
            "Train Epoch: 14 [49280/60000 (82%)]\tLoss: 0.002052\n",
            "Train Epoch: 14 [49920/60000 (83%)]\tLoss: 0.062369\n",
            "Train Epoch: 14 [50560/60000 (84%)]\tLoss: 0.010440\n",
            "Train Epoch: 14 [51200/60000 (85%)]\tLoss: 0.011054\n",
            "Train Epoch: 14 [51840/60000 (86%)]\tLoss: 0.004905\n",
            "Train Epoch: 14 [52480/60000 (87%)]\tLoss: 0.012033\n",
            "Train Epoch: 14 [53120/60000 (88%)]\tLoss: 0.016573\n",
            "Train Epoch: 14 [53760/60000 (90%)]\tLoss: 0.098505\n",
            "Train Epoch: 14 [54400/60000 (91%)]\tLoss: 0.002080\n",
            "Train Epoch: 14 [55040/60000 (92%)]\tLoss: 0.047064\n",
            "Train Epoch: 14 [55680/60000 (93%)]\tLoss: 0.001148\n",
            "Train Epoch: 14 [56320/60000 (94%)]\tLoss: 0.082663\n",
            "Train Epoch: 14 [56960/60000 (95%)]\tLoss: 0.017027\n",
            "Train Epoch: 14 [57600/60000 (96%)]\tLoss: 0.117999\n",
            "Train Epoch: 14 [58240/60000 (97%)]\tLoss: 0.039929\n",
            "Train Epoch: 14 [58880/60000 (98%)]\tLoss: 0.007420\n",
            "Train Epoch: 14 [59520/60000 (99%)]\tLoss: 0.053658\n",
            "\n",
            "Test set: Average loss: 0.0285, Accuracy: 9907/10000 (99%)\n",
            "\n",
            "Train Epoch: 14 [0/60000 (0%)]\tLoss: 0.017292\n",
            "Train Epoch: 14 [640/60000 (1%)]\tLoss: 0.066807\n",
            "Train Epoch: 14 [1280/60000 (2%)]\tLoss: 0.038271\n",
            "Train Epoch: 14 [1920/60000 (3%)]\tLoss: 0.162144\n",
            "Train Epoch: 14 [2560/60000 (4%)]\tLoss: 0.006849\n",
            "Train Epoch: 14 [3200/60000 (5%)]\tLoss: 0.001243\n",
            "Train Epoch: 14 [3840/60000 (6%)]\tLoss: 0.076517\n",
            "Train Epoch: 14 [4480/60000 (7%)]\tLoss: 0.002024\n",
            "Train Epoch: 14 [5120/60000 (9%)]\tLoss: 0.007213\n",
            "Train Epoch: 14 [5760/60000 (10%)]\tLoss: 0.002867\n",
            "Train Epoch: 14 [6400/60000 (11%)]\tLoss: 0.007732\n",
            "Train Epoch: 14 [7040/60000 (12%)]\tLoss: 0.037935\n",
            "Train Epoch: 14 [7680/60000 (13%)]\tLoss: 0.007638\n",
            "Train Epoch: 14 [8320/60000 (14%)]\tLoss: 0.010588\n",
            "Train Epoch: 14 [8960/60000 (15%)]\tLoss: 0.012714\n",
            "Train Epoch: 14 [9600/60000 (16%)]\tLoss: 0.007892\n",
            "Train Epoch: 14 [10240/60000 (17%)]\tLoss: 0.016606\n",
            "Train Epoch: 14 [10880/60000 (18%)]\tLoss: 0.040802\n",
            "Train Epoch: 14 [11520/60000 (19%)]\tLoss: 0.058434\n",
            "Train Epoch: 14 [12160/60000 (20%)]\tLoss: 0.097908\n",
            "Train Epoch: 14 [12800/60000 (21%)]\tLoss: 0.006868\n",
            "Train Epoch: 14 [13440/60000 (22%)]\tLoss: 0.003869\n",
            "Train Epoch: 14 [14080/60000 (23%)]\tLoss: 0.019701\n",
            "Train Epoch: 14 [14720/60000 (25%)]\tLoss: 0.034546\n",
            "Train Epoch: 14 [15360/60000 (26%)]\tLoss: 0.020445\n",
            "Train Epoch: 14 [16000/60000 (27%)]\tLoss: 0.019320\n",
            "Train Epoch: 14 [16640/60000 (28%)]\tLoss: 0.014315\n",
            "Train Epoch: 14 [17280/60000 (29%)]\tLoss: 0.113356\n",
            "Train Epoch: 14 [17920/60000 (30%)]\tLoss: 0.007018\n",
            "Train Epoch: 14 [18560/60000 (31%)]\tLoss: 0.016525\n",
            "Train Epoch: 14 [19200/60000 (32%)]\tLoss: 0.032414\n",
            "Train Epoch: 14 [19840/60000 (33%)]\tLoss: 0.003997\n",
            "Train Epoch: 14 [20480/60000 (34%)]\tLoss: 0.015035\n",
            "Train Epoch: 14 [21120/60000 (35%)]\tLoss: 0.021863\n",
            "Train Epoch: 14 [21760/60000 (36%)]\tLoss: 0.019614\n",
            "Train Epoch: 14 [22400/60000 (37%)]\tLoss: 0.077424\n",
            "Train Epoch: 14 [23040/60000 (38%)]\tLoss: 0.019707\n",
            "Train Epoch: 14 [23680/60000 (39%)]\tLoss: 0.130480\n",
            "Train Epoch: 14 [24320/60000 (41%)]\tLoss: 0.001235\n",
            "Train Epoch: 14 [24960/60000 (42%)]\tLoss: 0.006156\n",
            "Train Epoch: 14 [25600/60000 (43%)]\tLoss: 0.003786\n",
            "Train Epoch: 14 [26240/60000 (44%)]\tLoss: 0.010540\n",
            "Train Epoch: 14 [26880/60000 (45%)]\tLoss: 0.016792\n",
            "Train Epoch: 14 [27520/60000 (46%)]\tLoss: 0.013394\n",
            "Train Epoch: 14 [28160/60000 (47%)]\tLoss: 0.021930\n",
            "Train Epoch: 14 [28800/60000 (48%)]\tLoss: 0.027167\n",
            "Train Epoch: 14 [29440/60000 (49%)]\tLoss: 0.006378\n",
            "Train Epoch: 14 [30080/60000 (50%)]\tLoss: 0.003998\n",
            "Train Epoch: 14 [30720/60000 (51%)]\tLoss: 0.038917\n",
            "Train Epoch: 14 [31360/60000 (52%)]\tLoss: 0.036741\n",
            "Train Epoch: 14 [32000/60000 (53%)]\tLoss: 0.004515\n",
            "Train Epoch: 14 [32640/60000 (54%)]\tLoss: 0.002629\n",
            "Train Epoch: 14 [33280/60000 (55%)]\tLoss: 0.020876\n",
            "Train Epoch: 14 [33920/60000 (57%)]\tLoss: 0.042715\n",
            "Train Epoch: 14 [34560/60000 (58%)]\tLoss: 0.075339\n",
            "Train Epoch: 14 [35200/60000 (59%)]\tLoss: 0.017176\n",
            "Train Epoch: 14 [35840/60000 (60%)]\tLoss: 0.066618\n",
            "Train Epoch: 14 [36480/60000 (61%)]\tLoss: 0.004903\n",
            "Train Epoch: 14 [37120/60000 (62%)]\tLoss: 0.030724\n",
            "Train Epoch: 14 [37760/60000 (63%)]\tLoss: 0.007247\n",
            "Train Epoch: 14 [38400/60000 (64%)]\tLoss: 0.035072\n",
            "Train Epoch: 14 [39040/60000 (65%)]\tLoss: 0.024146\n",
            "Train Epoch: 14 [39680/60000 (66%)]\tLoss: 0.015949\n",
            "Train Epoch: 14 [40320/60000 (67%)]\tLoss: 0.000909\n",
            "Train Epoch: 14 [40960/60000 (68%)]\tLoss: 0.007471\n",
            "Train Epoch: 14 [41600/60000 (69%)]\tLoss: 0.064715\n",
            "Train Epoch: 14 [42240/60000 (70%)]\tLoss: 0.049311\n",
            "Train Epoch: 14 [42880/60000 (71%)]\tLoss: 0.142159\n",
            "Train Epoch: 14 [43520/60000 (72%)]\tLoss: 0.012124\n",
            "Train Epoch: 14 [44160/60000 (74%)]\tLoss: 0.007720\n",
            "Train Epoch: 14 [44800/60000 (75%)]\tLoss: 0.001695\n",
            "Train Epoch: 14 [45440/60000 (76%)]\tLoss: 0.037611\n",
            "Train Epoch: 14 [46080/60000 (77%)]\tLoss: 0.086503\n",
            "Train Epoch: 14 [46720/60000 (78%)]\tLoss: 0.024578\n",
            "Train Epoch: 14 [47360/60000 (79%)]\tLoss: 0.001942\n",
            "Train Epoch: 14 [48000/60000 (80%)]\tLoss: 0.009414\n",
            "Train Epoch: 14 [48640/60000 (81%)]\tLoss: 0.149671\n",
            "Train Epoch: 14 [49280/60000 (82%)]\tLoss: 0.009472\n",
            "Train Epoch: 14 [49920/60000 (83%)]\tLoss: 0.013553\n",
            "Train Epoch: 14 [50560/60000 (84%)]\tLoss: 0.086330\n",
            "Train Epoch: 14 [51200/60000 (85%)]\tLoss: 0.031075\n",
            "Train Epoch: 14 [51840/60000 (86%)]\tLoss: 0.055648\n",
            "Train Epoch: 14 [52480/60000 (87%)]\tLoss: 0.114099\n",
            "Train Epoch: 14 [53120/60000 (88%)]\tLoss: 0.033858\n",
            "Train Epoch: 14 [53760/60000 (90%)]\tLoss: 0.001019\n",
            "Train Epoch: 14 [54400/60000 (91%)]\tLoss: 0.012811\n",
            "Train Epoch: 14 [55040/60000 (92%)]\tLoss: 0.089384\n",
            "Train Epoch: 14 [55680/60000 (93%)]\tLoss: 0.013258\n",
            "Train Epoch: 14 [56320/60000 (94%)]\tLoss: 0.003553\n",
            "Train Epoch: 14 [56960/60000 (95%)]\tLoss: 0.079927\n",
            "Train Epoch: 14 [57600/60000 (96%)]\tLoss: 0.005103\n",
            "Train Epoch: 14 [58240/60000 (97%)]\tLoss: 0.004693\n",
            "Train Epoch: 14 [58880/60000 (98%)]\tLoss: 0.011697\n",
            "Train Epoch: 14 [59520/60000 (99%)]\tLoss: 0.027130\n",
            "\n",
            "Test set: Average loss: 0.0293, Accuracy: 9907/10000 (99%)\n",
            "\n",
            "Train Epoch: 14 [0/60000 (0%)]\tLoss: 0.061996\n",
            "Train Epoch: 14 [640/60000 (1%)]\tLoss: 0.007334\n",
            "Train Epoch: 14 [1280/60000 (2%)]\tLoss: 0.023506\n",
            "Train Epoch: 14 [1920/60000 (3%)]\tLoss: 0.080275\n",
            "Train Epoch: 14 [2560/60000 (4%)]\tLoss: 0.017920\n",
            "Train Epoch: 14 [3200/60000 (5%)]\tLoss: 0.022567\n",
            "Train Epoch: 14 [3840/60000 (6%)]\tLoss: 0.202077\n",
            "Train Epoch: 14 [4480/60000 (7%)]\tLoss: 0.001198\n",
            "Train Epoch: 14 [5120/60000 (9%)]\tLoss: 0.007148\n",
            "Train Epoch: 14 [5760/60000 (10%)]\tLoss: 0.068268\n",
            "Train Epoch: 14 [6400/60000 (11%)]\tLoss: 0.176140\n",
            "Train Epoch: 14 [7040/60000 (12%)]\tLoss: 0.004139\n",
            "Train Epoch: 14 [7680/60000 (13%)]\tLoss: 0.029538\n",
            "Train Epoch: 14 [8320/60000 (14%)]\tLoss: 0.105983\n",
            "Train Epoch: 14 [8960/60000 (15%)]\tLoss: 0.007888\n",
            "Train Epoch: 14 [9600/60000 (16%)]\tLoss: 0.012675\n",
            "Train Epoch: 14 [10240/60000 (17%)]\tLoss: 0.012398\n",
            "Train Epoch: 14 [10880/60000 (18%)]\tLoss: 0.010054\n",
            "Train Epoch: 14 [11520/60000 (19%)]\tLoss: 0.010776\n",
            "Train Epoch: 14 [12160/60000 (20%)]\tLoss: 0.004655\n",
            "Train Epoch: 14 [12800/60000 (21%)]\tLoss: 0.011149\n",
            "Train Epoch: 14 [13440/60000 (22%)]\tLoss: 0.002914\n",
            "Train Epoch: 14 [14080/60000 (23%)]\tLoss: 0.014026\n",
            "Train Epoch: 14 [14720/60000 (25%)]\tLoss: 0.017083\n",
            "Train Epoch: 14 [15360/60000 (26%)]\tLoss: 0.000463\n",
            "Train Epoch: 14 [16000/60000 (27%)]\tLoss: 0.001294\n",
            "Train Epoch: 14 [16640/60000 (28%)]\tLoss: 0.004657\n",
            "Train Epoch: 14 [17280/60000 (29%)]\tLoss: 0.007071\n",
            "Train Epoch: 14 [17920/60000 (30%)]\tLoss: 0.019668\n",
            "Train Epoch: 14 [18560/60000 (31%)]\tLoss: 0.067664\n",
            "Train Epoch: 14 [19200/60000 (32%)]\tLoss: 0.040330\n",
            "Train Epoch: 14 [19840/60000 (33%)]\tLoss: 0.018014\n",
            "Train Epoch: 14 [20480/60000 (34%)]\tLoss: 0.032038\n",
            "Train Epoch: 14 [21120/60000 (35%)]\tLoss: 0.024070\n",
            "Train Epoch: 14 [21760/60000 (36%)]\tLoss: 0.017483\n",
            "Train Epoch: 14 [22400/60000 (37%)]\tLoss: 0.006460\n",
            "Train Epoch: 14 [23040/60000 (38%)]\tLoss: 0.064237\n",
            "Train Epoch: 14 [23680/60000 (39%)]\tLoss: 0.009407\n",
            "Train Epoch: 14 [24320/60000 (41%)]\tLoss: 0.005091\n",
            "Train Epoch: 14 [24960/60000 (42%)]\tLoss: 0.028455\n",
            "Train Epoch: 14 [25600/60000 (43%)]\tLoss: 0.041755\n",
            "Train Epoch: 14 [26240/60000 (44%)]\tLoss: 0.008529\n",
            "Train Epoch: 14 [26880/60000 (45%)]\tLoss: 0.031964\n",
            "Train Epoch: 14 [27520/60000 (46%)]\tLoss: 0.015361\n",
            "Train Epoch: 14 [28160/60000 (47%)]\tLoss: 0.031692\n",
            "Train Epoch: 14 [28800/60000 (48%)]\tLoss: 0.003831\n",
            "Train Epoch: 14 [29440/60000 (49%)]\tLoss: 0.006146\n",
            "Train Epoch: 14 [30080/60000 (50%)]\tLoss: 0.001002\n",
            "Train Epoch: 14 [30720/60000 (51%)]\tLoss: 0.002449\n",
            "Train Epoch: 14 [31360/60000 (52%)]\tLoss: 0.111010\n",
            "Train Epoch: 14 [32000/60000 (53%)]\tLoss: 0.013086\n",
            "Train Epoch: 14 [32640/60000 (54%)]\tLoss: 0.001025\n",
            "Train Epoch: 14 [33280/60000 (55%)]\tLoss: 0.050875\n",
            "Train Epoch: 14 [33920/60000 (57%)]\tLoss: 0.007502\n",
            "Train Epoch: 14 [34560/60000 (58%)]\tLoss: 0.053484\n",
            "Train Epoch: 14 [35200/60000 (59%)]\tLoss: 0.005986\n",
            "Train Epoch: 14 [35840/60000 (60%)]\tLoss: 0.027988\n",
            "Train Epoch: 14 [36480/60000 (61%)]\tLoss: 0.004770\n",
            "Train Epoch: 14 [37120/60000 (62%)]\tLoss: 0.023212\n",
            "Train Epoch: 14 [37760/60000 (63%)]\tLoss: 0.002574\n",
            "Train Epoch: 14 [38400/60000 (64%)]\tLoss: 0.016831\n",
            "Train Epoch: 14 [39040/60000 (65%)]\tLoss: 0.138900\n",
            "Train Epoch: 14 [39680/60000 (66%)]\tLoss: 0.044925\n",
            "Train Epoch: 14 [40320/60000 (67%)]\tLoss: 0.004701\n",
            "Train Epoch: 14 [40960/60000 (68%)]\tLoss: 0.025336\n",
            "Train Epoch: 14 [41600/60000 (69%)]\tLoss: 0.048740\n",
            "Train Epoch: 14 [42240/60000 (70%)]\tLoss: 0.045994\n",
            "Train Epoch: 14 [42880/60000 (71%)]\tLoss: 0.001539\n",
            "Train Epoch: 14 [43520/60000 (72%)]\tLoss: 0.077726\n",
            "Train Epoch: 14 [44160/60000 (74%)]\tLoss: 0.012590\n",
            "Train Epoch: 14 [44800/60000 (75%)]\tLoss: 0.014673\n",
            "Train Epoch: 14 [45440/60000 (76%)]\tLoss: 0.002714\n",
            "Train Epoch: 14 [46080/60000 (77%)]\tLoss: 0.051554\n",
            "Train Epoch: 14 [46720/60000 (78%)]\tLoss: 0.042715\n",
            "Train Epoch: 14 [47360/60000 (79%)]\tLoss: 0.000532\n",
            "Train Epoch: 14 [48000/60000 (80%)]\tLoss: 0.010776\n",
            "Train Epoch: 14 [48640/60000 (81%)]\tLoss: 0.046615\n",
            "Train Epoch: 14 [49280/60000 (82%)]\tLoss: 0.003207\n",
            "Train Epoch: 14 [49920/60000 (83%)]\tLoss: 0.004259\n",
            "Train Epoch: 14 [50560/60000 (84%)]\tLoss: 0.054894\n",
            "Train Epoch: 14 [51200/60000 (85%)]\tLoss: 0.016962\n",
            "Train Epoch: 14 [51840/60000 (86%)]\tLoss: 0.001755\n",
            "Train Epoch: 14 [52480/60000 (87%)]\tLoss: 0.002512\n",
            "Train Epoch: 14 [53120/60000 (88%)]\tLoss: 0.018679\n",
            "Train Epoch: 14 [53760/60000 (90%)]\tLoss: 0.021890\n",
            "Train Epoch: 14 [54400/60000 (91%)]\tLoss: 0.003808\n",
            "Train Epoch: 14 [55040/60000 (92%)]\tLoss: 0.007571\n",
            "Train Epoch: 14 [55680/60000 (93%)]\tLoss: 0.042443\n",
            "Train Epoch: 14 [56320/60000 (94%)]\tLoss: 0.008142\n",
            "Train Epoch: 14 [56960/60000 (95%)]\tLoss: 0.005798\n",
            "Train Epoch: 14 [57600/60000 (96%)]\tLoss: 0.067521\n",
            "Train Epoch: 14 [58240/60000 (97%)]\tLoss: 0.017335\n",
            "Train Epoch: 14 [58880/60000 (98%)]\tLoss: 0.002154\n",
            "Train Epoch: 14 [59520/60000 (99%)]\tLoss: 0.007879\n",
            "\n",
            "Test set: Average loss: 0.0282, Accuracy: 9909/10000 (99%)\n",
            "\n",
            "Train Epoch: 14 [0/60000 (0%)]\tLoss: 0.002686\n",
            "Train Epoch: 14 [640/60000 (1%)]\tLoss: 0.004286\n",
            "Train Epoch: 14 [1280/60000 (2%)]\tLoss: 0.000861\n",
            "Train Epoch: 14 [1920/60000 (3%)]\tLoss: 0.062323\n",
            "Train Epoch: 14 [2560/60000 (4%)]\tLoss: 0.003997\n",
            "Train Epoch: 14 [3200/60000 (5%)]\tLoss: 0.003946\n",
            "Train Epoch: 14 [3840/60000 (6%)]\tLoss: 0.008847\n",
            "Train Epoch: 14 [4480/60000 (7%)]\tLoss: 0.036463\n",
            "Train Epoch: 14 [5120/60000 (9%)]\tLoss: 0.001577\n",
            "Train Epoch: 14 [5760/60000 (10%)]\tLoss: 0.001215\n",
            "Train Epoch: 14 [6400/60000 (11%)]\tLoss: 0.113315\n",
            "Train Epoch: 14 [7040/60000 (12%)]\tLoss: 0.002048\n",
            "Train Epoch: 14 [7680/60000 (13%)]\tLoss: 0.024189\n",
            "Train Epoch: 14 [8320/60000 (14%)]\tLoss: 0.022604\n",
            "Train Epoch: 14 [8960/60000 (15%)]\tLoss: 0.044958\n",
            "Train Epoch: 14 [9600/60000 (16%)]\tLoss: 0.110825\n",
            "Train Epoch: 14 [10240/60000 (17%)]\tLoss: 0.024175\n",
            "Train Epoch: 14 [10880/60000 (18%)]\tLoss: 0.028940\n",
            "Train Epoch: 14 [11520/60000 (19%)]\tLoss: 0.007063\n",
            "Train Epoch: 14 [12160/60000 (20%)]\tLoss: 0.124725\n",
            "Train Epoch: 14 [12800/60000 (21%)]\tLoss: 0.032904\n",
            "Train Epoch: 14 [13440/60000 (22%)]\tLoss: 0.026375\n",
            "Train Epoch: 14 [14080/60000 (23%)]\tLoss: 0.008489\n",
            "Train Epoch: 14 [14720/60000 (25%)]\tLoss: 0.022619\n",
            "Train Epoch: 14 [15360/60000 (26%)]\tLoss: 0.043303\n",
            "Train Epoch: 14 [16000/60000 (27%)]\tLoss: 0.007160\n",
            "Train Epoch: 14 [16640/60000 (28%)]\tLoss: 0.008846\n",
            "Train Epoch: 14 [17280/60000 (29%)]\tLoss: 0.030139\n",
            "Train Epoch: 14 [17920/60000 (30%)]\tLoss: 0.002602\n",
            "Train Epoch: 14 [18560/60000 (31%)]\tLoss: 0.023915\n",
            "Train Epoch: 14 [19200/60000 (32%)]\tLoss: 0.053820\n",
            "Train Epoch: 14 [19840/60000 (33%)]\tLoss: 0.011658\n",
            "Train Epoch: 14 [20480/60000 (34%)]\tLoss: 0.010216\n",
            "Train Epoch: 14 [21120/60000 (35%)]\tLoss: 0.043443\n",
            "Train Epoch: 14 [21760/60000 (36%)]\tLoss: 0.005379\n",
            "Train Epoch: 14 [22400/60000 (37%)]\tLoss: 0.128153\n",
            "Train Epoch: 14 [23040/60000 (38%)]\tLoss: 0.024757\n",
            "Train Epoch: 14 [23680/60000 (39%)]\tLoss: 0.000906\n",
            "Train Epoch: 14 [24320/60000 (41%)]\tLoss: 0.007985\n",
            "Train Epoch: 14 [24960/60000 (42%)]\tLoss: 0.013072\n",
            "Train Epoch: 14 [25600/60000 (43%)]\tLoss: 0.033117\n",
            "Train Epoch: 14 [26240/60000 (44%)]\tLoss: 0.035094\n",
            "Train Epoch: 14 [26880/60000 (45%)]\tLoss: 0.004918\n",
            "Train Epoch: 14 [27520/60000 (46%)]\tLoss: 0.005633\n",
            "Train Epoch: 14 [28160/60000 (47%)]\tLoss: 0.030268\n",
            "Train Epoch: 14 [28800/60000 (48%)]\tLoss: 0.068159\n",
            "Train Epoch: 14 [29440/60000 (49%)]\tLoss: 0.017578\n",
            "Train Epoch: 14 [30080/60000 (50%)]\tLoss: 0.024420\n",
            "Train Epoch: 14 [30720/60000 (51%)]\tLoss: 0.027480\n",
            "Train Epoch: 14 [31360/60000 (52%)]\tLoss: 0.012257\n",
            "Train Epoch: 14 [32000/60000 (53%)]\tLoss: 0.015692\n",
            "Train Epoch: 14 [32640/60000 (54%)]\tLoss: 0.007782\n",
            "Train Epoch: 14 [33280/60000 (55%)]\tLoss: 0.006197\n",
            "Train Epoch: 14 [33920/60000 (57%)]\tLoss: 0.005580\n",
            "Train Epoch: 14 [34560/60000 (58%)]\tLoss: 0.003839\n",
            "Train Epoch: 14 [35200/60000 (59%)]\tLoss: 0.003356\n",
            "Train Epoch: 14 [35840/60000 (60%)]\tLoss: 0.073628\n",
            "Train Epoch: 14 [36480/60000 (61%)]\tLoss: 0.030116\n",
            "Train Epoch: 14 [37120/60000 (62%)]\tLoss: 0.041331\n",
            "Train Epoch: 14 [37760/60000 (63%)]\tLoss: 0.016072\n",
            "Train Epoch: 14 [38400/60000 (64%)]\tLoss: 0.002227\n",
            "Train Epoch: 14 [39040/60000 (65%)]\tLoss: 0.003490\n",
            "Train Epoch: 14 [39680/60000 (66%)]\tLoss: 0.001891\n",
            "Train Epoch: 14 [40320/60000 (67%)]\tLoss: 0.028105\n",
            "Train Epoch: 14 [40960/60000 (68%)]\tLoss: 0.035768\n",
            "Train Epoch: 14 [41600/60000 (69%)]\tLoss: 0.001743\n",
            "Train Epoch: 14 [42240/60000 (70%)]\tLoss: 0.013173\n",
            "Train Epoch: 14 [42880/60000 (71%)]\tLoss: 0.031472\n",
            "Train Epoch: 14 [43520/60000 (72%)]\tLoss: 0.066815\n",
            "Train Epoch: 14 [44160/60000 (74%)]\tLoss: 0.004052\n",
            "Train Epoch: 14 [44800/60000 (75%)]\tLoss: 0.068360\n",
            "Train Epoch: 14 [45440/60000 (76%)]\tLoss: 0.012884\n",
            "Train Epoch: 14 [46080/60000 (77%)]\tLoss: 0.024664\n",
            "Train Epoch: 14 [46720/60000 (78%)]\tLoss: 0.033992\n",
            "Train Epoch: 14 [47360/60000 (79%)]\tLoss: 0.009246\n",
            "Train Epoch: 14 [48000/60000 (80%)]\tLoss: 0.120566\n",
            "Train Epoch: 14 [48640/60000 (81%)]\tLoss: 0.009423\n",
            "Train Epoch: 14 [49280/60000 (82%)]\tLoss: 0.006862\n",
            "Train Epoch: 14 [49920/60000 (83%)]\tLoss: 0.006852\n",
            "Train Epoch: 14 [50560/60000 (84%)]\tLoss: 0.004211\n",
            "Train Epoch: 14 [51200/60000 (85%)]\tLoss: 0.037901\n",
            "Train Epoch: 14 [51840/60000 (86%)]\tLoss: 0.003162\n",
            "Train Epoch: 14 [52480/60000 (87%)]\tLoss: 0.002580\n",
            "Train Epoch: 14 [53120/60000 (88%)]\tLoss: 0.016486\n",
            "Train Epoch: 14 [53760/60000 (90%)]\tLoss: 0.057814\n",
            "Train Epoch: 14 [54400/60000 (91%)]\tLoss: 0.003572\n",
            "Train Epoch: 14 [55040/60000 (92%)]\tLoss: 0.007959\n",
            "Train Epoch: 14 [55680/60000 (93%)]\tLoss: 0.017261\n",
            "Train Epoch: 14 [56320/60000 (94%)]\tLoss: 0.015415\n",
            "Train Epoch: 14 [56960/60000 (95%)]\tLoss: 0.024083\n",
            "Train Epoch: 14 [57600/60000 (96%)]\tLoss: 0.004677\n",
            "Train Epoch: 14 [58240/60000 (97%)]\tLoss: 0.033680\n",
            "Train Epoch: 14 [58880/60000 (98%)]\tLoss: 0.004139\n",
            "Train Epoch: 14 [59520/60000 (99%)]\tLoss: 0.043729\n",
            "\n",
            "Test set: Average loss: 0.0277, Accuracy: 9910/10000 (99%)\n",
            "\n",
            "Train Epoch: 14 [0/60000 (0%)]\tLoss: 0.000369\n",
            "Train Epoch: 14 [640/60000 (1%)]\tLoss: 0.022865\n",
            "Train Epoch: 14 [1280/60000 (2%)]\tLoss: 0.047446\n",
            "Train Epoch: 14 [1920/60000 (3%)]\tLoss: 0.002876\n",
            "Train Epoch: 14 [2560/60000 (4%)]\tLoss: 0.027107\n",
            "Train Epoch: 14 [3200/60000 (5%)]\tLoss: 0.002349\n",
            "Train Epoch: 14 [3840/60000 (6%)]\tLoss: 0.022971\n",
            "Train Epoch: 14 [4480/60000 (7%)]\tLoss: 0.006938\n",
            "Train Epoch: 14 [5120/60000 (9%)]\tLoss: 0.037714\n",
            "Train Epoch: 14 [5760/60000 (10%)]\tLoss: 0.017109\n",
            "Train Epoch: 14 [6400/60000 (11%)]\tLoss: 0.036222\n",
            "Train Epoch: 14 [7040/60000 (12%)]\tLoss: 0.030088\n",
            "Train Epoch: 14 [7680/60000 (13%)]\tLoss: 0.119682\n",
            "Train Epoch: 14 [8320/60000 (14%)]\tLoss: 0.008728\n",
            "Train Epoch: 14 [8960/60000 (15%)]\tLoss: 0.001612\n",
            "Train Epoch: 14 [9600/60000 (16%)]\tLoss: 0.012016\n",
            "Train Epoch: 14 [10240/60000 (17%)]\tLoss: 0.010993\n",
            "Train Epoch: 14 [10880/60000 (18%)]\tLoss: 0.002663\n",
            "Train Epoch: 14 [11520/60000 (19%)]\tLoss: 0.014999\n",
            "Train Epoch: 14 [12160/60000 (20%)]\tLoss: 0.007516\n",
            "Train Epoch: 14 [12800/60000 (21%)]\tLoss: 0.036451\n",
            "Train Epoch: 14 [13440/60000 (22%)]\tLoss: 0.018407\n",
            "Train Epoch: 14 [14080/60000 (23%)]\tLoss: 0.016312\n",
            "Train Epoch: 14 [14720/60000 (25%)]\tLoss: 0.036114\n",
            "Train Epoch: 14 [15360/60000 (26%)]\tLoss: 0.016868\n",
            "Train Epoch: 14 [16000/60000 (27%)]\tLoss: 0.005271\n",
            "Train Epoch: 14 [16640/60000 (28%)]\tLoss: 0.001658\n",
            "Train Epoch: 14 [17280/60000 (29%)]\tLoss: 0.000945\n",
            "Train Epoch: 14 [17920/60000 (30%)]\tLoss: 0.011020\n",
            "Train Epoch: 14 [18560/60000 (31%)]\tLoss: 0.015325\n",
            "Train Epoch: 14 [19200/60000 (32%)]\tLoss: 0.024110\n",
            "Train Epoch: 14 [19840/60000 (33%)]\tLoss: 0.010577\n",
            "Train Epoch: 14 [20480/60000 (34%)]\tLoss: 0.080441\n",
            "Train Epoch: 14 [21120/60000 (35%)]\tLoss: 0.033438\n",
            "Train Epoch: 14 [21760/60000 (36%)]\tLoss: 0.021296\n",
            "Train Epoch: 14 [22400/60000 (37%)]\tLoss: 0.001575\n",
            "Train Epoch: 14 [23040/60000 (38%)]\tLoss: 0.000769\n",
            "Train Epoch: 14 [23680/60000 (39%)]\tLoss: 0.049870\n",
            "Train Epoch: 14 [24320/60000 (41%)]\tLoss: 0.029557\n",
            "Train Epoch: 14 [24960/60000 (42%)]\tLoss: 0.053719\n",
            "Train Epoch: 14 [25600/60000 (43%)]\tLoss: 0.005084\n",
            "Train Epoch: 14 [26240/60000 (44%)]\tLoss: 0.006431\n",
            "Train Epoch: 14 [26880/60000 (45%)]\tLoss: 0.018612\n",
            "Train Epoch: 14 [27520/60000 (46%)]\tLoss: 0.026232\n",
            "Train Epoch: 14 [28160/60000 (47%)]\tLoss: 0.001046\n",
            "Train Epoch: 14 [28800/60000 (48%)]\tLoss: 0.002056\n",
            "Train Epoch: 14 [29440/60000 (49%)]\tLoss: 0.024243\n",
            "Train Epoch: 14 [30080/60000 (50%)]\tLoss: 0.027149\n",
            "Train Epoch: 14 [30720/60000 (51%)]\tLoss: 0.000816\n",
            "Train Epoch: 14 [31360/60000 (52%)]\tLoss: 0.004920\n",
            "Train Epoch: 14 [32000/60000 (53%)]\tLoss: 0.037315\n",
            "Train Epoch: 14 [32640/60000 (54%)]\tLoss: 0.003668\n",
            "Train Epoch: 14 [33280/60000 (55%)]\tLoss: 0.006996\n",
            "Train Epoch: 14 [33920/60000 (57%)]\tLoss: 0.024173\n",
            "Train Epoch: 14 [34560/60000 (58%)]\tLoss: 0.029115\n",
            "Train Epoch: 14 [35200/60000 (59%)]\tLoss: 0.009189\n",
            "Train Epoch: 14 [35840/60000 (60%)]\tLoss: 0.006073\n",
            "Train Epoch: 14 [36480/60000 (61%)]\tLoss: 0.023206\n",
            "Train Epoch: 14 [37120/60000 (62%)]\tLoss: 0.040444\n",
            "Train Epoch: 14 [37760/60000 (63%)]\tLoss: 0.043183\n",
            "Train Epoch: 14 [38400/60000 (64%)]\tLoss: 0.014930\n",
            "Train Epoch: 14 [39040/60000 (65%)]\tLoss: 0.031746\n",
            "Train Epoch: 14 [39680/60000 (66%)]\tLoss: 0.041734\n",
            "Train Epoch: 14 [40320/60000 (67%)]\tLoss: 0.018275\n",
            "Train Epoch: 14 [40960/60000 (68%)]\tLoss: 0.002667\n",
            "Train Epoch: 14 [41600/60000 (69%)]\tLoss: 0.013410\n",
            "Train Epoch: 14 [42240/60000 (70%)]\tLoss: 0.130195\n",
            "Train Epoch: 14 [42880/60000 (71%)]\tLoss: 0.059805\n",
            "Train Epoch: 14 [43520/60000 (72%)]\tLoss: 0.086336\n",
            "Train Epoch: 14 [44160/60000 (74%)]\tLoss: 0.093795\n",
            "Train Epoch: 14 [44800/60000 (75%)]\tLoss: 0.072092\n",
            "Train Epoch: 14 [45440/60000 (76%)]\tLoss: 0.120292\n",
            "Train Epoch: 14 [46080/60000 (77%)]\tLoss: 0.013264\n",
            "Train Epoch: 14 [46720/60000 (78%)]\tLoss: 0.058066\n",
            "Train Epoch: 14 [47360/60000 (79%)]\tLoss: 0.052797\n",
            "Train Epoch: 14 [48000/60000 (80%)]\tLoss: 0.010133\n",
            "Train Epoch: 14 [48640/60000 (81%)]\tLoss: 0.009563\n",
            "Train Epoch: 14 [49280/60000 (82%)]\tLoss: 0.005622\n",
            "Train Epoch: 14 [49920/60000 (83%)]\tLoss: 0.018560\n",
            "Train Epoch: 14 [50560/60000 (84%)]\tLoss: 0.116393\n",
            "Train Epoch: 14 [51200/60000 (85%)]\tLoss: 0.022353\n",
            "Train Epoch: 14 [51840/60000 (86%)]\tLoss: 0.010091\n",
            "Train Epoch: 14 [52480/60000 (87%)]\tLoss: 0.001892\n",
            "Train Epoch: 14 [53120/60000 (88%)]\tLoss: 0.002197\n",
            "Train Epoch: 14 [53760/60000 (90%)]\tLoss: 0.040728\n",
            "Train Epoch: 14 [54400/60000 (91%)]\tLoss: 0.105554\n",
            "Train Epoch: 14 [55040/60000 (92%)]\tLoss: 0.053824\n",
            "Train Epoch: 14 [55680/60000 (93%)]\tLoss: 0.095345\n",
            "Train Epoch: 14 [56320/60000 (94%)]\tLoss: 0.008385\n",
            "Train Epoch: 14 [56960/60000 (95%)]\tLoss: 0.046640\n",
            "Train Epoch: 14 [57600/60000 (96%)]\tLoss: 0.043886\n",
            "Train Epoch: 14 [58240/60000 (97%)]\tLoss: 0.058488\n",
            "Train Epoch: 14 [58880/60000 (98%)]\tLoss: 0.026980\n",
            "Train Epoch: 14 [59520/60000 (99%)]\tLoss: 0.026024\n",
            "\n",
            "Test set: Average loss: 0.0283, Accuracy: 9910/10000 (99%)\n",
            "\n",
            "Train Epoch: 14 [0/60000 (0%)]\tLoss: 0.012147\n",
            "Train Epoch: 14 [640/60000 (1%)]\tLoss: 0.050716\n",
            "Train Epoch: 14 [1280/60000 (2%)]\tLoss: 0.019798\n",
            "Train Epoch: 14 [1920/60000 (3%)]\tLoss: 0.007854\n",
            "Train Epoch: 14 [2560/60000 (4%)]\tLoss: 0.017578\n",
            "Train Epoch: 14 [3200/60000 (5%)]\tLoss: 0.079241\n",
            "Train Epoch: 14 [3840/60000 (6%)]\tLoss: 0.024250\n",
            "Train Epoch: 14 [4480/60000 (7%)]\tLoss: 0.011580\n",
            "Train Epoch: 14 [5120/60000 (9%)]\tLoss: 0.005186\n",
            "Train Epoch: 14 [5760/60000 (10%)]\tLoss: 0.004726\n",
            "Train Epoch: 14 [6400/60000 (11%)]\tLoss: 0.019004\n",
            "Train Epoch: 14 [7040/60000 (12%)]\tLoss: 0.098074\n",
            "Train Epoch: 14 [7680/60000 (13%)]\tLoss: 0.084892\n",
            "Train Epoch: 14 [8320/60000 (14%)]\tLoss: 0.003131\n",
            "Train Epoch: 14 [8960/60000 (15%)]\tLoss: 0.004431\n",
            "Train Epoch: 14 [9600/60000 (16%)]\tLoss: 0.014005\n",
            "Train Epoch: 14 [10240/60000 (17%)]\tLoss: 0.006360\n",
            "Train Epoch: 14 [10880/60000 (18%)]\tLoss: 0.055790\n",
            "Train Epoch: 14 [11520/60000 (19%)]\tLoss: 0.029971\n",
            "Train Epoch: 14 [12160/60000 (20%)]\tLoss: 0.026096\n",
            "Train Epoch: 14 [12800/60000 (21%)]\tLoss: 0.002254\n",
            "Train Epoch: 14 [13440/60000 (22%)]\tLoss: 0.019981\n",
            "Train Epoch: 14 [14080/60000 (23%)]\tLoss: 0.018484\n",
            "Train Epoch: 14 [14720/60000 (25%)]\tLoss: 0.003021\n",
            "Train Epoch: 14 [15360/60000 (26%)]\tLoss: 0.015272\n",
            "Train Epoch: 14 [16000/60000 (27%)]\tLoss: 0.108930\n",
            "Train Epoch: 14 [16640/60000 (28%)]\tLoss: 0.020197\n",
            "Train Epoch: 14 [17280/60000 (29%)]\tLoss: 0.172339\n",
            "Train Epoch: 14 [17920/60000 (30%)]\tLoss: 0.118996\n",
            "Train Epoch: 14 [18560/60000 (31%)]\tLoss: 0.120935\n",
            "Train Epoch: 14 [19200/60000 (32%)]\tLoss: 0.135826\n",
            "Train Epoch: 14 [19840/60000 (33%)]\tLoss: 0.019130\n",
            "Train Epoch: 14 [20480/60000 (34%)]\tLoss: 0.010777\n",
            "Train Epoch: 14 [21120/60000 (35%)]\tLoss: 0.080982\n",
            "Train Epoch: 14 [21760/60000 (36%)]\tLoss: 0.006541\n",
            "Train Epoch: 14 [22400/60000 (37%)]\tLoss: 0.120194\n",
            "Train Epoch: 14 [23040/60000 (38%)]\tLoss: 0.020304\n",
            "Train Epoch: 14 [23680/60000 (39%)]\tLoss: 0.003514\n",
            "Train Epoch: 14 [24320/60000 (41%)]\tLoss: 0.058357\n",
            "Train Epoch: 14 [24960/60000 (42%)]\tLoss: 0.050638\n",
            "Train Epoch: 14 [25600/60000 (43%)]\tLoss: 0.019145\n",
            "Train Epoch: 14 [26240/60000 (44%)]\tLoss: 0.008072\n",
            "Train Epoch: 14 [26880/60000 (45%)]\tLoss: 0.011138\n",
            "Train Epoch: 14 [27520/60000 (46%)]\tLoss: 0.018915\n",
            "Train Epoch: 14 [28160/60000 (47%)]\tLoss: 0.018189\n",
            "Train Epoch: 14 [28800/60000 (48%)]\tLoss: 0.006952\n",
            "Train Epoch: 14 [29440/60000 (49%)]\tLoss: 0.017451\n",
            "Train Epoch: 14 [30080/60000 (50%)]\tLoss: 0.006030\n",
            "Train Epoch: 14 [30720/60000 (51%)]\tLoss: 0.019151\n",
            "Train Epoch: 14 [31360/60000 (52%)]\tLoss: 0.010798\n",
            "Train Epoch: 14 [32000/60000 (53%)]\tLoss: 0.104397\n",
            "Train Epoch: 14 [32640/60000 (54%)]\tLoss: 0.007105\n",
            "Train Epoch: 14 [33280/60000 (55%)]\tLoss: 0.010126\n",
            "Train Epoch: 14 [33920/60000 (57%)]\tLoss: 0.003736\n",
            "Train Epoch: 14 [34560/60000 (58%)]\tLoss: 0.030092\n",
            "Train Epoch: 14 [35200/60000 (59%)]\tLoss: 0.014767\n",
            "Train Epoch: 14 [35840/60000 (60%)]\tLoss: 0.035834\n",
            "Train Epoch: 14 [36480/60000 (61%)]\tLoss: 0.000603\n",
            "Train Epoch: 14 [37120/60000 (62%)]\tLoss: 0.024234\n",
            "Train Epoch: 14 [37760/60000 (63%)]\tLoss: 0.001622\n",
            "Train Epoch: 14 [38400/60000 (64%)]\tLoss: 0.012441\n",
            "Train Epoch: 14 [39040/60000 (65%)]\tLoss: 0.026822\n",
            "Train Epoch: 14 [39680/60000 (66%)]\tLoss: 0.003863\n",
            "Train Epoch: 14 [40320/60000 (67%)]\tLoss: 0.027468\n",
            "Train Epoch: 14 [40960/60000 (68%)]\tLoss: 0.002647\n",
            "Train Epoch: 14 [41600/60000 (69%)]\tLoss: 0.004905\n",
            "Train Epoch: 14 [42240/60000 (70%)]\tLoss: 0.160602\n",
            "Train Epoch: 14 [42880/60000 (71%)]\tLoss: 0.021227\n",
            "Train Epoch: 14 [43520/60000 (72%)]\tLoss: 0.001981\n",
            "Train Epoch: 14 [44160/60000 (74%)]\tLoss: 0.027316\n",
            "Train Epoch: 14 [44800/60000 (75%)]\tLoss: 0.008130\n",
            "Train Epoch: 14 [45440/60000 (76%)]\tLoss: 0.007182\n",
            "Train Epoch: 14 [46080/60000 (77%)]\tLoss: 0.021132\n",
            "Train Epoch: 14 [46720/60000 (78%)]\tLoss: 0.015123\n",
            "Train Epoch: 14 [47360/60000 (79%)]\tLoss: 0.029303\n",
            "Train Epoch: 14 [48000/60000 (80%)]\tLoss: 0.119844\n",
            "Train Epoch: 14 [48640/60000 (81%)]\tLoss: 0.007616\n",
            "Train Epoch: 14 [49280/60000 (82%)]\tLoss: 0.016403\n",
            "Train Epoch: 14 [49920/60000 (83%)]\tLoss: 0.016317\n",
            "Train Epoch: 14 [50560/60000 (84%)]\tLoss: 0.043891\n",
            "Train Epoch: 14 [51200/60000 (85%)]\tLoss: 0.073327\n",
            "Train Epoch: 14 [51840/60000 (86%)]\tLoss: 0.036913\n",
            "Train Epoch: 14 [52480/60000 (87%)]\tLoss: 0.004253\n",
            "Train Epoch: 14 [53120/60000 (88%)]\tLoss: 0.029276\n",
            "Train Epoch: 14 [53760/60000 (90%)]\tLoss: 0.033484\n",
            "Train Epoch: 14 [54400/60000 (91%)]\tLoss: 0.003045\n",
            "Train Epoch: 14 [55040/60000 (92%)]\tLoss: 0.005130\n",
            "Train Epoch: 14 [55680/60000 (93%)]\tLoss: 0.021138\n",
            "Train Epoch: 14 [56320/60000 (94%)]\tLoss: 0.088303\n",
            "Train Epoch: 14 [56960/60000 (95%)]\tLoss: 0.026230\n",
            "Train Epoch: 14 [57600/60000 (96%)]\tLoss: 0.010514\n",
            "Train Epoch: 14 [58240/60000 (97%)]\tLoss: 0.006207\n",
            "Train Epoch: 14 [58880/60000 (98%)]\tLoss: 0.099039\n",
            "Train Epoch: 14 [59520/60000 (99%)]\tLoss: 0.004433\n",
            "\n",
            "Test set: Average loss: 0.0278, Accuracy: 9907/10000 (99%)\n",
            "\n",
            "Train Epoch: 14 [0/60000 (0%)]\tLoss: 0.002702\n",
            "Train Epoch: 14 [640/60000 (1%)]\tLoss: 0.022930\n",
            "Train Epoch: 14 [1280/60000 (2%)]\tLoss: 0.049862\n",
            "Train Epoch: 14 [1920/60000 (3%)]\tLoss: 0.097768\n",
            "Train Epoch: 14 [2560/60000 (4%)]\tLoss: 0.112718\n",
            "Train Epoch: 14 [3200/60000 (5%)]\tLoss: 0.018136\n",
            "Train Epoch: 14 [3840/60000 (6%)]\tLoss: 0.006604\n",
            "Train Epoch: 14 [4480/60000 (7%)]\tLoss: 0.006823\n",
            "Train Epoch: 14 [5120/60000 (9%)]\tLoss: 0.031079\n",
            "Train Epoch: 14 [5760/60000 (10%)]\tLoss: 0.002974\n",
            "Train Epoch: 14 [6400/60000 (11%)]\tLoss: 0.005471\n",
            "Train Epoch: 14 [7040/60000 (12%)]\tLoss: 0.012286\n",
            "Train Epoch: 14 [7680/60000 (13%)]\tLoss: 0.005400\n",
            "Train Epoch: 14 [8320/60000 (14%)]\tLoss: 0.027177\n",
            "Train Epoch: 14 [8960/60000 (15%)]\tLoss: 0.008860\n",
            "Train Epoch: 14 [9600/60000 (16%)]\tLoss: 0.020042\n",
            "Train Epoch: 14 [10240/60000 (17%)]\tLoss: 0.022261\n",
            "Train Epoch: 14 [10880/60000 (18%)]\tLoss: 0.020165\n",
            "Train Epoch: 14 [11520/60000 (19%)]\tLoss: 0.056684\n",
            "Train Epoch: 14 [12160/60000 (20%)]\tLoss: 0.025611\n",
            "Train Epoch: 14 [12800/60000 (21%)]\tLoss: 0.001644\n",
            "Train Epoch: 14 [13440/60000 (22%)]\tLoss: 0.012991\n",
            "Train Epoch: 14 [14080/60000 (23%)]\tLoss: 0.065828\n",
            "Train Epoch: 14 [14720/60000 (25%)]\tLoss: 0.054138\n",
            "Train Epoch: 14 [15360/60000 (26%)]\tLoss: 0.026186\n",
            "Train Epoch: 14 [16000/60000 (27%)]\tLoss: 0.031951\n",
            "Train Epoch: 14 [16640/60000 (28%)]\tLoss: 0.000520\n",
            "Train Epoch: 14 [17280/60000 (29%)]\tLoss: 0.017084\n",
            "Train Epoch: 14 [17920/60000 (30%)]\tLoss: 0.014194\n",
            "Train Epoch: 14 [18560/60000 (31%)]\tLoss: 0.012748\n",
            "Train Epoch: 14 [19200/60000 (32%)]\tLoss: 0.001699\n",
            "Train Epoch: 14 [19840/60000 (33%)]\tLoss: 0.058555\n",
            "Train Epoch: 14 [20480/60000 (34%)]\tLoss: 0.002365\n",
            "Train Epoch: 14 [21120/60000 (35%)]\tLoss: 0.017726\n",
            "Train Epoch: 14 [21760/60000 (36%)]\tLoss: 0.006031\n",
            "Train Epoch: 14 [22400/60000 (37%)]\tLoss: 0.003226\n",
            "Train Epoch: 14 [23040/60000 (38%)]\tLoss: 0.005676\n",
            "Train Epoch: 14 [23680/60000 (39%)]\tLoss: 0.005964\n",
            "Train Epoch: 14 [24320/60000 (41%)]\tLoss: 0.030148\n",
            "Train Epoch: 14 [24960/60000 (42%)]\tLoss: 0.090410\n",
            "Train Epoch: 14 [25600/60000 (43%)]\tLoss: 0.021194\n",
            "Train Epoch: 14 [26240/60000 (44%)]\tLoss: 0.001081\n",
            "Train Epoch: 14 [26880/60000 (45%)]\tLoss: 0.117791\n",
            "Train Epoch: 14 [27520/60000 (46%)]\tLoss: 0.025274\n",
            "Train Epoch: 14 [28160/60000 (47%)]\tLoss: 0.003144\n",
            "Train Epoch: 14 [28800/60000 (48%)]\tLoss: 0.002355\n",
            "Train Epoch: 14 [29440/60000 (49%)]\tLoss: 0.024984\n",
            "Train Epoch: 14 [30080/60000 (50%)]\tLoss: 0.010579\n",
            "Train Epoch: 14 [30720/60000 (51%)]\tLoss: 0.007280\n",
            "Train Epoch: 14 [31360/60000 (52%)]\tLoss: 0.001733\n",
            "Train Epoch: 14 [32000/60000 (53%)]\tLoss: 0.130714\n",
            "Train Epoch: 14 [32640/60000 (54%)]\tLoss: 0.007166\n",
            "Train Epoch: 14 [33280/60000 (55%)]\tLoss: 0.010625\n",
            "Train Epoch: 14 [33920/60000 (57%)]\tLoss: 0.112831\n",
            "Train Epoch: 14 [34560/60000 (58%)]\tLoss: 0.041696\n",
            "Train Epoch: 14 [35200/60000 (59%)]\tLoss: 0.024368\n",
            "Train Epoch: 14 [35840/60000 (60%)]\tLoss: 0.056137\n",
            "Train Epoch: 14 [36480/60000 (61%)]\tLoss: 0.079642\n",
            "Train Epoch: 14 [37120/60000 (62%)]\tLoss: 0.001717\n",
            "Train Epoch: 14 [37760/60000 (63%)]\tLoss: 0.010782\n",
            "Train Epoch: 14 [38400/60000 (64%)]\tLoss: 0.042812\n",
            "Train Epoch: 14 [39040/60000 (65%)]\tLoss: 0.108707\n",
            "Train Epoch: 14 [39680/60000 (66%)]\tLoss: 0.005540\n",
            "Train Epoch: 14 [40320/60000 (67%)]\tLoss: 0.024197\n",
            "Train Epoch: 14 [40960/60000 (68%)]\tLoss: 0.056223\n",
            "Train Epoch: 14 [41600/60000 (69%)]\tLoss: 0.054944\n",
            "Train Epoch: 14 [42240/60000 (70%)]\tLoss: 0.033299\n",
            "Train Epoch: 14 [42880/60000 (71%)]\tLoss: 0.028140\n",
            "Train Epoch: 14 [43520/60000 (72%)]\tLoss: 0.057619\n",
            "Train Epoch: 14 [44160/60000 (74%)]\tLoss: 0.027635\n",
            "Train Epoch: 14 [44800/60000 (75%)]\tLoss: 0.029556\n",
            "Train Epoch: 14 [45440/60000 (76%)]\tLoss: 0.004251\n",
            "Train Epoch: 14 [46080/60000 (77%)]\tLoss: 0.019376\n",
            "Train Epoch: 14 [46720/60000 (78%)]\tLoss: 0.018540\n",
            "Train Epoch: 14 [47360/60000 (79%)]\tLoss: 0.002938\n",
            "Train Epoch: 14 [48000/60000 (80%)]\tLoss: 0.044587\n",
            "Train Epoch: 14 [48640/60000 (81%)]\tLoss: 0.002998\n",
            "Train Epoch: 14 [49280/60000 (82%)]\tLoss: 0.013277\n",
            "Train Epoch: 14 [49920/60000 (83%)]\tLoss: 0.054557\n",
            "Train Epoch: 14 [50560/60000 (84%)]\tLoss: 0.061147\n",
            "Train Epoch: 14 [51200/60000 (85%)]\tLoss: 0.003223\n",
            "Train Epoch: 14 [51840/60000 (86%)]\tLoss: 0.012446\n",
            "Train Epoch: 14 [52480/60000 (87%)]\tLoss: 0.023190\n",
            "Train Epoch: 14 [53120/60000 (88%)]\tLoss: 0.001336\n",
            "Train Epoch: 14 [53760/60000 (90%)]\tLoss: 0.015491\n",
            "Train Epoch: 14 [54400/60000 (91%)]\tLoss: 0.013916\n",
            "Train Epoch: 14 [55040/60000 (92%)]\tLoss: 0.050085\n",
            "Train Epoch: 14 [55680/60000 (93%)]\tLoss: 0.013422\n",
            "Train Epoch: 14 [56320/60000 (94%)]\tLoss: 0.007451\n",
            "Train Epoch: 14 [56960/60000 (95%)]\tLoss: 0.011774\n",
            "Train Epoch: 14 [57600/60000 (96%)]\tLoss: 0.016074\n",
            "Train Epoch: 14 [58240/60000 (97%)]\tLoss: 0.042045\n",
            "Train Epoch: 14 [58880/60000 (98%)]\tLoss: 0.002092\n",
            "Train Epoch: 14 [59520/60000 (99%)]\tLoss: 0.062951\n",
            "\n",
            "Test set: Average loss: 0.0272, Accuracy: 9914/10000 (99%)\n",
            "\n",
            "Train Epoch: 14 [0/60000 (0%)]\tLoss: 0.003014\n",
            "Train Epoch: 14 [640/60000 (1%)]\tLoss: 0.011061\n",
            "Train Epoch: 14 [1280/60000 (2%)]\tLoss: 0.013647\n",
            "Train Epoch: 14 [1920/60000 (3%)]\tLoss: 0.140408\n",
            "Train Epoch: 14 [2560/60000 (4%)]\tLoss: 0.020211\n",
            "Train Epoch: 14 [3200/60000 (5%)]\tLoss: 0.003922\n",
            "Train Epoch: 14 [3840/60000 (6%)]\tLoss: 0.022399\n",
            "Train Epoch: 14 [4480/60000 (7%)]\tLoss: 0.008191\n",
            "Train Epoch: 14 [5120/60000 (9%)]\tLoss: 0.012288\n",
            "Train Epoch: 14 [5760/60000 (10%)]\tLoss: 0.025941\n",
            "Train Epoch: 14 [6400/60000 (11%)]\tLoss: 0.015652\n",
            "Train Epoch: 14 [7040/60000 (12%)]\tLoss: 0.003958\n",
            "Train Epoch: 14 [7680/60000 (13%)]\tLoss: 0.012695\n",
            "Train Epoch: 14 [8320/60000 (14%)]\tLoss: 0.004817\n",
            "Train Epoch: 14 [8960/60000 (15%)]\tLoss: 0.004693\n",
            "Train Epoch: 14 [9600/60000 (16%)]\tLoss: 0.077777\n",
            "Train Epoch: 14 [10240/60000 (17%)]\tLoss: 0.007063\n",
            "Train Epoch: 14 [10880/60000 (18%)]\tLoss: 0.001557\n",
            "Train Epoch: 14 [11520/60000 (19%)]\tLoss: 0.142851\n",
            "Train Epoch: 14 [12160/60000 (20%)]\tLoss: 0.063360\n",
            "Train Epoch: 14 [12800/60000 (21%)]\tLoss: 0.010936\n",
            "Train Epoch: 14 [13440/60000 (22%)]\tLoss: 0.065413\n",
            "Train Epoch: 14 [14080/60000 (23%)]\tLoss: 0.153050\n",
            "Train Epoch: 14 [14720/60000 (25%)]\tLoss: 0.039493\n",
            "Train Epoch: 14 [15360/60000 (26%)]\tLoss: 0.008563\n",
            "Train Epoch: 14 [16000/60000 (27%)]\tLoss: 0.004851\n",
            "Train Epoch: 14 [16640/60000 (28%)]\tLoss: 0.058433\n",
            "Train Epoch: 14 [17280/60000 (29%)]\tLoss: 0.026050\n",
            "Train Epoch: 14 [17920/60000 (30%)]\tLoss: 0.117993\n",
            "Train Epoch: 14 [18560/60000 (31%)]\tLoss: 0.022256\n",
            "Train Epoch: 14 [19200/60000 (32%)]\tLoss: 0.002864\n",
            "Train Epoch: 14 [19840/60000 (33%)]\tLoss: 0.011411\n",
            "Train Epoch: 14 [20480/60000 (34%)]\tLoss: 0.052515\n",
            "Train Epoch: 14 [21120/60000 (35%)]\tLoss: 0.037998\n",
            "Train Epoch: 14 [21760/60000 (36%)]\tLoss: 0.000636\n",
            "Train Epoch: 14 [22400/60000 (37%)]\tLoss: 0.140970\n",
            "Train Epoch: 14 [23040/60000 (38%)]\tLoss: 0.003713\n",
            "Train Epoch: 14 [23680/60000 (39%)]\tLoss: 0.028475\n",
            "Train Epoch: 14 [24320/60000 (41%)]\tLoss: 0.009801\n",
            "Train Epoch: 14 [24960/60000 (42%)]\tLoss: 0.004607\n",
            "Train Epoch: 14 [25600/60000 (43%)]\tLoss: 0.007838\n",
            "Train Epoch: 14 [26240/60000 (44%)]\tLoss: 0.024914\n",
            "Train Epoch: 14 [26880/60000 (45%)]\tLoss: 0.014936\n",
            "Train Epoch: 14 [27520/60000 (46%)]\tLoss: 0.012285\n",
            "Train Epoch: 14 [28160/60000 (47%)]\tLoss: 0.008226\n",
            "Train Epoch: 14 [28800/60000 (48%)]\tLoss: 0.005031\n",
            "Train Epoch: 14 [29440/60000 (49%)]\tLoss: 0.031309\n",
            "Train Epoch: 14 [30080/60000 (50%)]\tLoss: 0.023660\n",
            "Train Epoch: 14 [30720/60000 (51%)]\tLoss: 0.003087\n",
            "Train Epoch: 14 [31360/60000 (52%)]\tLoss: 0.007570\n",
            "Train Epoch: 14 [32000/60000 (53%)]\tLoss: 0.005398\n",
            "Train Epoch: 14 [32640/60000 (54%)]\tLoss: 0.051294\n",
            "Train Epoch: 14 [33280/60000 (55%)]\tLoss: 0.016120\n",
            "Train Epoch: 14 [33920/60000 (57%)]\tLoss: 0.001251\n",
            "Train Epoch: 14 [34560/60000 (58%)]\tLoss: 0.139076\n",
            "Train Epoch: 14 [35200/60000 (59%)]\tLoss: 0.005477\n",
            "Train Epoch: 14 [35840/60000 (60%)]\tLoss: 0.029757\n",
            "Train Epoch: 14 [36480/60000 (61%)]\tLoss: 0.051156\n",
            "Train Epoch: 14 [37120/60000 (62%)]\tLoss: 0.011716\n",
            "Train Epoch: 14 [37760/60000 (63%)]\tLoss: 0.008270\n",
            "Train Epoch: 14 [38400/60000 (64%)]\tLoss: 0.046126\n",
            "Train Epoch: 14 [39040/60000 (65%)]\tLoss: 0.002609\n",
            "Train Epoch: 14 [39680/60000 (66%)]\tLoss: 0.008535\n",
            "Train Epoch: 14 [40320/60000 (67%)]\tLoss: 0.003979\n",
            "Train Epoch: 14 [40960/60000 (68%)]\tLoss: 0.002046\n",
            "Train Epoch: 14 [41600/60000 (69%)]\tLoss: 0.022834\n",
            "Train Epoch: 14 [42240/60000 (70%)]\tLoss: 0.003654\n",
            "Train Epoch: 14 [42880/60000 (71%)]\tLoss: 0.015079\n",
            "Train Epoch: 14 [43520/60000 (72%)]\tLoss: 0.072972\n",
            "Train Epoch: 14 [44160/60000 (74%)]\tLoss: 0.008900\n",
            "Train Epoch: 14 [44800/60000 (75%)]\tLoss: 0.113056\n",
            "Train Epoch: 14 [45440/60000 (76%)]\tLoss: 0.003801\n",
            "Train Epoch: 14 [46080/60000 (77%)]\tLoss: 0.108255\n",
            "Train Epoch: 14 [46720/60000 (78%)]\tLoss: 0.045202\n",
            "Train Epoch: 14 [47360/60000 (79%)]\tLoss: 0.030820\n",
            "Train Epoch: 14 [48000/60000 (80%)]\tLoss: 0.004216\n",
            "Train Epoch: 14 [48640/60000 (81%)]\tLoss: 0.002432\n",
            "Train Epoch: 14 [49280/60000 (82%)]\tLoss: 0.004170\n",
            "Train Epoch: 14 [49920/60000 (83%)]\tLoss: 0.011350\n",
            "Train Epoch: 14 [50560/60000 (84%)]\tLoss: 0.207634\n",
            "Train Epoch: 14 [51200/60000 (85%)]\tLoss: 0.006325\n",
            "Train Epoch: 14 [51840/60000 (86%)]\tLoss: 0.041012\n",
            "Train Epoch: 14 [52480/60000 (87%)]\tLoss: 0.010049\n",
            "Train Epoch: 14 [53120/60000 (88%)]\tLoss: 0.011639\n",
            "Train Epoch: 14 [53760/60000 (90%)]\tLoss: 0.061581\n",
            "Train Epoch: 14 [54400/60000 (91%)]\tLoss: 0.001142\n",
            "Train Epoch: 14 [55040/60000 (92%)]\tLoss: 0.014130\n",
            "Train Epoch: 14 [55680/60000 (93%)]\tLoss: 0.001755\n",
            "Train Epoch: 14 [56320/60000 (94%)]\tLoss: 0.115990\n",
            "Train Epoch: 14 [56960/60000 (95%)]\tLoss: 0.016395\n",
            "Train Epoch: 14 [57600/60000 (96%)]\tLoss: 0.063757\n",
            "Train Epoch: 14 [58240/60000 (97%)]\tLoss: 0.003656\n",
            "Train Epoch: 14 [58880/60000 (98%)]\tLoss: 0.005240\n",
            "Train Epoch: 14 [59520/60000 (99%)]\tLoss: 0.001646\n",
            "\n",
            "Test set: Average loss: 0.0275, Accuracy: 9913/10000 (99%)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ltsr1tE-3o4Z"
      },
      "source": [
        "### Training and Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kAg4fEcS9156"
      },
      "source": [
        "## VAE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DoZjwrH3xpei"
      },
      "source": [
        "#SEED = 100\n",
        "\n",
        "LAT_DIM = 2\n",
        "EPOCH_NUM = 50\n",
        "CAPACITY = 64\n",
        "LRN_RATE = 1e-3\n",
        "VAR_BETA = 1\n",
        "\n",
        "KERN_SIZE = 4\n",
        "STRIDE = 2\n",
        "PAD = 1"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UkcWN5LXyCEo"
      },
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Encoder, self).__init__()\n",
        "        \n",
        "        # CAPACITY * 14 * 14\n",
        "        self.conv1 = nn.Conv2d(\n",
        "            in_channels = 1,\n",
        "            out_channels = CAPACITY,\n",
        "            kernel_size = KERN_SIZE,\n",
        "            stride = STRIDE,\n",
        "            padding = PAD,\n",
        "        )\n",
        "        # CAPACITY * 7 * 7\n",
        "        self.conv2 = nn.Conv2d(\n",
        "            in_channels = CAPACITY,\n",
        "            out_channels = CAPACITY * 2,\n",
        "            kernel_size = KERN_SIZE,\n",
        "            stride = STRIDE,\n",
        "            padding = PAD,\n",
        "        )\n",
        "        self.fc_mu = nn.Linear(\n",
        "            in_features = CAPACITY * 2 * 7 * 7,\n",
        "            out_features = LAT_DIM,\n",
        "        )\n",
        "        self.fc_logvar = nn.Linear(\n",
        "            in_features = CAPACITY * 2 * 7 * 7,\n",
        "            out_features = LAT_DIM,\n",
        "        )\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = cnn.hidden_layers(x)\n",
        "\n",
        "        x = F.relu(self.conv2(\n",
        "            F.relu(self.conv1(x))\n",
        "        ))\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x_mu = self.fc_mu(x)\n",
        "        x_logvar = self.fc_logvar(x)\n",
        "        return x_mu, x_logvar"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        },
        "id": "86cSR8lZ4AK7",
        "outputId": "b61dfe5c-bcdb-4155-d45b-8566998a2269"
      },
      "source": [
        "vae1 = train_one_model()\n",
        "vae2 = train_one_model()"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of parameters: 311429\n",
            "Training: "
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-52-dddc9d0f330d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvae1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_one_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mvae2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_one_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-38-5db18f6b5ea3>\u001b[0m in \u001b[0;36mtrain_one_model\u001b[0;34m(evaluate)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0;31m# vae reconstruction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m             \u001b[0mimage_batch_recon\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlatent_mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlatent_logvar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvae\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0;31m# reconstruction error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-34-17db98f62180>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mlatent_mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlatent_logvar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mlatent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatent_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlatent_mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlatent_logvar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mx_recon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlatent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-51-6076ab703f3f>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         x = F.relu(self.conv2(\n\u001b[0;32m---> 34\u001b[0;31m             \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         ))\n\u001b[1;32m     36\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 423\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight)\u001b[0m\n\u001b[1;32m    418\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    419\u001b[0m         return F.conv2d(input, weight, self.bias, self.stride,\n\u001b[0;32m--> 420\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Expected 4-dimensional input for 4-dimensional weight [64, 4, 4, 4], but got 2-dimensional input of size [128, 10] instead"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "35jQ8f41zRFg"
      },
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Decoder, self).__init__()\n",
        "        \n",
        "        self.fc = nn.Linear(\n",
        "            in_features = LAT_DIM,\n",
        "            out_features = CAPACITY * 2 * 7 * 7,\n",
        "        )\n",
        "        self.conv2 = nn.ConvTranspose2d(\n",
        "            in_channels = CAPACITY * 2,\n",
        "            out_channels = CAPACITY,\n",
        "            kernel_size = KERN_SIZE,\n",
        "            stride = STRIDE,\n",
        "            padding = PAD,\n",
        "        )\n",
        "        self.conv1 = nn.ConvTranspose2d(\n",
        "            in_channels = CAPACITY,\n",
        "            out_channels = 1,\n",
        "            kernel_size = KERN_SIZE,\n",
        "            stride = STRIDE,\n",
        "            padding = PAD,\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc(x)\n",
        "        return torch.sigmoid(self.conv1(\n",
        "                F.relu(self.conv2(\n",
        "                    x.view(x.size(0), CAPACITY * 2, 7, 7)\n",
        "            ))\n",
        "        ))"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PCQPtw5a3DQI"
      },
      "source": [
        "class VariationalAutoencoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(VariationalAutoencoder, self).__init__()\n",
        "        \n",
        "        self.encoder = Encoder()\n",
        "        self.decoder = Decoder()\n",
        "\n",
        "    def forward(self, x):\n",
        "        latent_mu, latent_logvar = self.encoder(x)\n",
        "        latent = self.latent_sample(latent_mu, latent_logvar)\n",
        "        x_recon = self.decoder(latent)\n",
        "        return x_recon, latent_mu, latent_logvar\n",
        "\n",
        "    def latent_sample(self, mu, logvar):\n",
        "        if self.training:\n",
        "            # the reparameterization trick\n",
        "            std = logvar.mul(0.5).exp_()\n",
        "            eps = torch.empty_like(std).normal_()\n",
        "            return eps.mul(std).add_(mu)\n",
        "        else:\n",
        "            return mu"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e2CrBYQU4e8r"
      },
      "source": [
        "def reconstruction_error(recon_x, x):\n",
        "    return F.binary_cross_entropy(\n",
        "        recon_x.view(-1, 784),\n",
        "        x.view(-1, 784),\n",
        "        reduction = \"sum\",\n",
        "    )\n",
        "\n",
        "def vae_loss(recon_loss, mu, logvar):\n",
        "    kl_divergence = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
        "    return recon_loss + VAR_BETA * kl_divergence"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N7XQuBW63DmN"
      },
      "source": [
        "### Training and Evaluation\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2FVd05s4I4YM"
      },
      "source": [
        "def plot_loss(train_losses, test_losses):\n",
        "    plt.ion()\n",
        "\n",
        "    plotlabels = [\"Total error\", \"Reconstruction error\"]\n",
        "    \n",
        "    ncols = 2\n",
        "    fig, ax = plt.subplots(ncols = ncols, figsize = (9, 2.5))\n",
        "    \n",
        "    for i in range(2): \n",
        "        ax[i].plot(train_losses[i], c = \"blue\", label = \"training\")\n",
        "        ax[i].plot(test_losses[i], c = \"red\", label = \"test\")\n",
        "            \n",
        "        ax[i].set_title(plotlabels[i])\n",
        "        \n",
        "    plt.xlabel('Epochs')\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel(y)\n",
        "    plt.legend()\n",
        "    plt.show()"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "isT5TzCPJEE1"
      },
      "source": [
        "def eval_model(vae):\n",
        "    vae.eval()\n",
        "    \n",
        "    test_loss_avg, test_recon_loss_avg, num_batches = 0, 0, 0\n",
        "    sum = 0\n",
        "    for image_batch, _ in test_dataloader:\n",
        "        \n",
        "        with torch.no_grad():\n",
        "        \n",
        "            image_batch = image_batch.to(device)\n",
        "    \n",
        "            # vae reconstruction\n",
        "            image_batch_recon, latent_mu, latent_logvar = vae(image_batch)\n",
        "    \n",
        "            # reconstruction error\n",
        "            recon_loss = reconstruction_error(image_batch_recon, image_batch)\n",
        "            loss = vae_loss(recon_loss, latent_mu, latent_logvar)\n",
        "    \n",
        "            test_recon_loss_avg += recon_loss\n",
        "            test_loss_avg += loss.item()\n",
        "            num_batches += 1\n",
        "        \n",
        "    test_recon_loss_avg /= num_batches\n",
        "    test_loss_avg /= num_batches\n",
        "\n",
        "    return test_recon_loss_avg, test_loss_avg\n",
        "    #print('average reconstruction error: %f' % (test_recon_loss_avg))\n",
        "    #print('average error: %f' % (test_loss_avg))"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lb5IpN6M3KKk"
      },
      "source": [
        "def train_one_model(evaluate = False):\n",
        "    \"\"\" Creates and trains one VAE model.\n",
        "\n",
        "    Args:\n",
        "        evaluate: Whether or not to evaluate model during training.\n",
        "\n",
        "    Returns:\n",
        "        Tuple containing the trained model, average training reconstruction\n",
        "        error, average total training error, average testing reconstruction\n",
        "        error, and average total testing error.\n",
        "    \"\"\"\n",
        "\n",
        "    #torch.cuda.manual_seed(SEED)\n",
        "    vae = VariationalAutoencoder()\n",
        "    vae = vae.to(device)\n",
        "    \n",
        "    num_params = sum(p.numel() for p in vae.parameters() if p.requires_grad)\n",
        "    print('Number of parameters: %d' % num_params)\n",
        "    \n",
        "    optimizer = torch.optim.Adam(\n",
        "        params = vae.parameters(),\n",
        "        lr = LRN_RATE,\n",
        "        weight_decay = 1e-5,\n",
        "    )\n",
        "    \n",
        "    # set to training mode\n",
        "    vae.train()\n",
        "    \n",
        "    if evaluate:\n",
        "        train_recon_loss, train_loss = [], []\n",
        "        test_recon_loss, test_loss = [], []\n",
        "    \n",
        "    print(\"Training: \", end = \"\")\n",
        "    for epoch in range(EPOCH_NUM):\n",
        "        if evaluate:\n",
        "            train_loss.append(0)\n",
        "            train_recon_loss.append(0)\n",
        "        num_batches = 0\n",
        "        \n",
        "        for image_batch, _ in train_dataloader:\n",
        "            \n",
        "            #image_batch = rot_transform(image_batch)\n",
        "            image_batch = image_batch.to(device)\n",
        "    \n",
        "            # vae reconstruction\n",
        "            image_batch_recon, latent_mu, latent_logvar = vae(image_batch)\n",
        "            \n",
        "            # reconstruction error\n",
        "            recon_loss = reconstruction_error(image_batch_recon, image_batch)\n",
        "            loss = vae_loss(recon_loss, latent_mu, latent_logvar)\n",
        "            \n",
        "            # backpropagation\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            \n",
        "            # one step of the optmizer (using the gradients from backpropagation)\n",
        "            optimizer.step()\n",
        "            \n",
        "            if evaluate:\n",
        "                train_loss[-1] += loss.item()\n",
        "                train_recon_loss[-1] += recon_loss\n",
        "                \n",
        "            num_batches += 1\n",
        "            \n",
        "        if evaluate:\n",
        "            train_loss[-1] /= num_batches\n",
        "            train_recon_loss[-1] /= num_batches\n",
        "        \n",
        "            recon_loss_avg, loss_avg = eval_model(vae)\n",
        "            test_recon_loss.append(recon_loss_avg)\n",
        "            test_loss.append(loss_avg)\n",
        "            vae.train()\n",
        "        \n",
        "        print(\"%d, \" % (epoch+1), end = \"\")\n",
        "        \n",
        "    print()\n",
        "    if evaluate: \n",
        "        plot_loss(\n",
        "            [train_loss, train_recon_loss],\n",
        "            [test_loss, test_recon_loss],\n",
        "        )\n",
        "        \n",
        "    return vae"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "idP_RI6bBttt"
      },
      "source": [
        "def train_and_test_models(\n",
        "    n, gamma_matrix, alpha_matrix, beta_matrix, evaluate = False,\n",
        "):\n",
        "    \"\"\"\n",
        "    Train n models and compute the MNIST heterogeneities on the models.\n",
        "\n",
        "    Returns:\n",
        "        Heterogeneity \"matrices\" that are lists of np arrrays.\n",
        "        matrix[i] is the heterogeneity array for vae_i\n",
        "        matrix[i][j] is the heterogeneity for digit_j for vae_i\n",
        "    \"\"\"\n",
        "    for _ in range(n):\n",
        "        vae = train_one_model(evaluate = evaluate)\n",
        "        \n",
        "        gammas, alphas, betas = calculate_rrh(vae)\n",
        "        gamma_matrix.append(gammas)\n",
        "        alpha_matrix.append(alphas)\n",
        "        beta_matrix.append(betas)\n",
        "    return gamma_matrix, alpha_matrix, beta_matrix\n",
        "\n",
        "def plot_rrh_matrices(gamma_matrix, alpha_matrix, beta_matrix):\n",
        "    gamma_avg = het_avg(gamma_matrix)\n",
        "    alpha_avg = het_avg(alpha_matrix)\n",
        "    beta_avg = het_avg(beta_matrix)\n",
        "    \n",
        "    gamma_sigma = het_sigma(gamma_matrix)\n",
        "    alpha_sigma = het_sigma(alpha_matrix)\n",
        "    beta_sigma = het_sigma(beta_matrix)\n",
        "    \n",
        "    plot_rrh(\n",
        "        gamma_avg, alpha_avg, beta_avg,\n",
        "        sigmas = [gamma_sigma, alpha_sigma, beta_sigma],\n",
        "    )"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bxImy1XR6FHR"
      },
      "source": [
        "## RRH for Gaussian Mixtures"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2H2L9XvS6Kwj"
      },
      "source": [
        "def mvn_renyi(C, q=1):\n",
        "    \"\"\" Computes the Rnyi heterogeneity for a multivariate Gaussian \n",
        "    Arguments: \n",
        "        C: `ndarray((n,n))`. Covariance matrix\n",
        "        q: `0<float`. Order of the heterogeneity\n",
        "    Returns: \n",
        "        `float`\n",
        "    \"\"\"\n",
        "    n = C.shape[0]\n",
        "    SqrtDetC = np.sqrt(np.linalg.det(C))\n",
        "    if q == 1: \n",
        "        out = (2*np.pi*np.e)**(n/2) * SqrtDetC\n",
        "    elif q == np.inf: \n",
        "        out = (2*np.pi)**(n/2) * SqrtDetC\n",
        "    elif q!=1 and q!=0 and q!=np.inf:\n",
        "        out = ((2*np.pi)**(n/2))*(q**(n/(2*(q-1))))*SqrtDetC\n",
        "    return out"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TkLYVMBu6fDn"
      },
      "source": [
        "def mvn_renyi_alpha(C,  q=1):\n",
        "    \"\"\" Computes the alpha-heterogeneity for a Gaussian mixture where each sample has equal weight\n",
        "\n",
        "    Arguments: \n",
        "\n",
        "        cov: `ndarray((nsamples, n, n))`. Covariance matrices \n",
        "        q: `0<float`. Order of the heterogeneity metric\n",
        "\n",
        "    Returns: \n",
        "\n",
        "        `float`. The alpha-heterogeneity\n",
        "    \"\"\"\n",
        "    K, n, _ = C.shape\n",
        "    p = np.repeat(1/K, K)\n",
        "    if q == 1:\n",
        "        out = np.exp((n + np.sum(p*np.log(np.linalg.det(2*np.pi*C))))/2)\n",
        "    elif q!=np.inf and q!=1 and q!=0:\n",
        "        wbar = (p**q)/np.sum(p**q)\n",
        "        out = ((2*np.pi)**(n/2))*np.sum(wbar*np.sqrt(np.linalg.det(C)))/(q**(n/2))**(1/(1-q))\n",
        "    return out\n"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4aDzvMEx_X9r"
      },
      "source": [
        "def scale_to_cov(scales):\n",
        "    return np.vstack([np.expand_dims(np.diagflat(s), 0) for s in scales])"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DS7dTSHl_e2i"
      },
      "source": [
        "def pool_covariance(means, covs):\n",
        "    K = covs.shape[0] \n",
        "    p = np.repeat(1/K, K)\n",
        "    cov_ = np.einsum('ijk,i->jk', covs, p) + np.einsum('ij,ik,i->jk', means, means, p)\n",
        "    mu_ = np.einsum('ij,i->j', means, p)\n",
        "    return cov_ - np.einsum('i,j->ij', mu_, mu_)"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RG67lA7u6pAY"
      },
      "source": [
        "### Computation and plotting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IinU-xeM6fg_"
      },
      "source": [
        "def calculate_rrh(vae, X = train_X, y = train_y):\n",
        "    gammas, alphas, betas = [], [], []\n",
        "    for i in range(10):\n",
        "        mu, logvar = vae.encoder(torch.Tensor(X[y == i]).to(device))\n",
        "        loc = mu.cpu().detach().numpy()\n",
        "        scale = logvar.exp().cpu().detach().numpy()\n",
        "        cov = scale_to_cov(scale)\n",
        "        gamma = mvn_renyi(pool_covariance(loc, cov), q=1)\n",
        "        alpha = mvn_renyi_alpha(cov,q=1)\n",
        "        beta = gamma/alpha\n",
        "        gammas.append(gamma)\n",
        "        alphas.append(alpha)\n",
        "        betas.append(beta)\n",
        "    return np.array(gammas), np.array(alphas), np.array(betas)"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xcRWRha365r-"
      },
      "source": [
        "def plot_rrh(gammas, alphas, betas, sigmas = None):\n",
        "    if not (len(gammas) == len(alphas) or len(gammas) == len(betas)):\n",
        "        sys.exit(\"Mismatched matrix size\")\n",
        "    n = len(gammas)\n",
        "    hetvalues = [gammas, alphas, betas]\n",
        "    plotlabels = [r\"Pooled\", r\"Within-Observation\", r\"Between-Observation\"]\n",
        "    \n",
        "    fig, ax = plt.subplots(ncols=3, figsize=(9, 2.5))\n",
        "    ax[0].set_ylabel(\"Heterogeneity\")\n",
        "    \n",
        "    for i in range(3): \n",
        "        ax[i].set_title(plotlabels[i])\n",
        "        ax[i].set_xlabel(\"Digit\")\n",
        "        ax[i].set_xticks(np.arange(10))\n",
        "        ax[i].set_xticklabels(np.arange(10))\n",
        "        ax[i].bar(\n",
        "            np.arange(10),\n",
        "            hetvalues[i],\n",
        "            facecolor = plt.get_cmap(\"Greys\")(0.4), \n",
        "            edgecolor = \"black\",\n",
        "        )\n",
        "        if not sigmas == None:\n",
        "            ax[i].errorbar(\n",
        "                np.arange(10),\n",
        "                hetvalues[i],\n",
        "                yerr = sigmas[i],\n",
        "                fmt = \"none\",\n",
        "                ecolor = \"r\",\n",
        "                capsize = 3,\n",
        "                label = \"std deviation\",\n",
        "            )\n",
        "            ax[i].errorbar(\n",
        "                np.arange(10),\n",
        "                hetvalues[i],\n",
        "                yerr = sigmas[i] / np.sqrt(n),\n",
        "                fmt = \"none\",\n",
        "                ecolor = \"b\",\n",
        "                capsize = 3,\n",
        "                label = \"std error\",\n",
        "            )\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    #plt.savefig(\"digit-class-heterogeneity.pdf\", bbox_inches=\"tight\")"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mOOtu98Jv1-_"
      },
      "source": [
        "def het_sigma(matrix, avg = None):\n",
        "    if avg == None:\n",
        "        avg = het_avg(matrix)\n",
        "    n = len(matrix)\n",
        "    mse = (matrix[0] - avg) ** 2\n",
        "    for i in range(1, n):\n",
        "        mse += (matrix[i] - avg) ** 2\n",
        "    return np.sqrt(mse / n)\n",
        "\n",
        "def het_sum(matrix):\n",
        "    sum = matrix[0] + matrix[1]\n",
        "    for i in range(2, len(matrix)):\n",
        "        sum += matrix[i]\n",
        "    return sum\n",
        "\n",
        "def het_avg(matrix):\n",
        "    return het_sum(matrix) / len(matrix)"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eM3hF-q0VipP"
      },
      "source": [
        "# Experiments"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bzmQvee5qsLp"
      },
      "source": [
        "\"\"\"\n",
        "N = 1\n",
        "n = 5\n",
        "gamma_matrix, alpha_matrix, beta_matrix = [], [], []\n",
        "for _ in range(N):\n",
        "    gamma_matrix, alpha_matrix, beta_matrix = train_and_test_models(\n",
        "        n, gamma_matrix, alpha_matrix, beta_matrix, evaluate = True,\n",
        "    )\n",
        "    plot_rrh_matrices(gamma_matrix, alpha_matrix, beta_matrix)\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lvx8i8Ct9yMR"
      },
      "source": [
        "## Load, Evaluate, and Plot RRH for Pre-Trained VAE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vNRYGlvQ5O77"
      },
      "source": [
        "def load_pretrained_vae():\n",
        "    pretrained_vae = VariationalAutoencoder()\n",
        "    pretrained_vae = pretrained_vae.to(device)\n",
        "    \n",
        "    filename = 'vae_2d.pth'\n",
        "    \n",
        "    if not os.path.isdir('./pretrained'):\n",
        "        os.makedirs('./pretrained')\n",
        "    urllib.request.urlretrieve(\n",
        "        \"http://geometry.cs.ucl.ac.uk/creativeai/pretrained/\" + filename,\n",
        "        \"./pretrained/\" + filename,\n",
        "    )\n",
        "    pretrained_vae.load_state_dict(torch.load('./pretrained/' + filename))\n",
        "    return pretrained_vae"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nRS4NG0mJJZY"
      },
      "source": [
        "pretrained_vae = load_pretrained_vae()\n",
        "eval_model(pretrained_vae)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_nN1Kftyh42Z"
      },
      "source": [
        "gammas, alphas, betas = calculate_rrh(pretrained_vae)\n",
        "plot_rrh(gammas, alphas, betas)\n",
        "\n",
        "gammas, alphas, betas = calculate_rrh(pretrained_vae, X = test_X, y = test_y)\n",
        "plot_rrh(gammas, alphas, betas)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vzodKmcX0SLi"
      },
      "source": [
        "def to_img(x):\n",
        "    x = x.clamp(0, 1)\n",
        "    return x\n",
        "\n",
        "def show_image(img):\n",
        "    img = to_img(img)\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "\n",
        "def visualize_latent_space(vae):\n",
        "    vae.eval()\n",
        "\n",
        "    bound = 2.5\n",
        "    nsteps = 20 \n",
        "    with torch.no_grad():\n",
        "        latent_x = np.linspace(-bound,bound,nsteps)\n",
        "        latent_y = np.linspace(-bound,bound,nsteps)\n",
        "        latents = torch.FloatTensor(len(latent_x), len(latent_y), 2)\n",
        "        for i, lx in enumerate(latent_x):\n",
        "            for j, ly in enumerate(latent_y):\n",
        "                latents[j, i, 0] = lx\n",
        "                latents[j, i, 1] = ly\n",
        "        latents = latents.view(-1, 2) # flatten grid into a batch\n",
        "    \n",
        "        # reconstruct images from the latent vectors\n",
        "        latents = latents.to(device)\n",
        "        image_recon = vae.decoder(latents)\n",
        "        image_recon = image_recon.cpu()\n",
        "    \n",
        "        fig, ax = plt.subplots(figsize=(10, 10))\n",
        "        show_image(\n",
        "            torchvision.utils.make_grid(\n",
        "                image_recon.data[:int(nsteps**2)], nsteps, 5,\n",
        "            )\n",
        "        )\n",
        "        ax.set_xticks([]); ax.set_xticklabels([])\n",
        "        ax.set_yticks([]); ax.set_yticklabels([])\n",
        "        #plt.savefig(\"latent-space-map.pdf\", bbox_inches=\"tight\")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8v0TSx231Las"
      },
      "source": [
        "visualize_latent_space(vae1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0_NVuvet7_e4"
      },
      "source": [
        "visualize_latent_space(vae2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LsksiYr20gME"
      },
      "source": [
        "visualize_latent_space(pretrained_vae)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fa8BsW-sxvOf"
      },
      "source": [
        "def visualise_output(images, model, title = \"DEFAULT\"):\n",
        "\n",
        "    with torch.no_grad():\n",
        "    \n",
        "        images = images.to(device)\n",
        "        images, _, _ = model(images)\n",
        "        images = images.cpu()\n",
        "        images = to_img(images)\n",
        "        np_imagegrid = torchvision.utils.make_grid(images[0:IMG_NUM], WIDTH, HEIGHT).numpy()\n",
        "        plt.imshow(np.transpose(np_imagegrid, (1, 2, 0)))\n",
        "        plt.title(title)\n",
        "        plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dxYy03Fdtlwn"
      },
      "source": [
        "IMG_NUM = 100\n",
        "WIDTH = 10\n",
        "HEIGHT = 10\n",
        "\n",
        "sns.set(style = \"dark\")\n",
        "\n",
        "images, labels = iter(test_dataloader).next()\n",
        "\n",
        "# First visualise the original images\n",
        "print('Original images')\n",
        "show_image(torchvision.utils.make_grid(images[0:IMG_NUM], WIDTH, HEIGHT))\n",
        "plt.title(\"Original\")\n",
        "plt.show()\n",
        "\n",
        "\n",
        "visualise_output(images, vae1, title = \"VAE 1\")\n",
        "\n",
        "visualise_output(images, vae2, title = \"VAE 2\")\n",
        "\n",
        "visualise_output(images, pretrained_vae, title = \"Pretrained VAE\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zjWWbUCA0oKk"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}