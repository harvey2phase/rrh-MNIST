{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "cnn_vae.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harvey2phase/rrh-MNIST/blob/main/cnn_vae.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nlBt0FWz8iXu"
      },
      "source": [
        "import os\n",
        "import urllib\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.utils\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import MNIST\n",
        "\n",
        "import seaborn as sns"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2JmIrFw-0GXL"
      },
      "source": [
        "sns.set()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TFpBblS_eLg1"
      },
      "source": [
        "GPU = True\n",
        "device = torch.device(\"cuda:0\" if GPU and torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hfwhdEx46mFx"
      },
      "source": [
        "# Load MNIST"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o8UxKtJy51hY"
      },
      "source": [
        "MAX_ROT_DEG = 15\n",
        "BATCH_SIZE = 128"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R9VbzfzV47ON"
      },
      "source": [
        "img_transform = transforms.Compose([\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "#rot_transform = transforms.RandomRotation(MAX_ROT_DEG)\n",
        "\n",
        "def load_mnist(train):\n",
        "    dataset = MNIST(\n",
        "        root = './data/MNIST',\n",
        "        download = True,\n",
        "        train = train,\n",
        "        transform = img_transform,\n",
        "    )\n",
        "    return DataLoader(dataset, batch_size = BATCH_SIZE, shuffle = True)\n",
        "\n",
        "train_dataloader = load_mnist(train = True)\n",
        "test_dataloader = load_mnist(train = False)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0IMlt_q67tJo"
      },
      "source": [
        "# Place into numpy arrays for easier manipulation\n",
        "traindata = list(train_dataloader)\n",
        "traindata = [[sample[0].numpy(), sample[1].numpy()] for sample in traindata]\n",
        "train_X = np.vstack([sample[0] for sample in traindata])\n",
        "train_y = np.hstack([sample[1] for sample in traindata])\n",
        "\n",
        "testdata = list(test_dataloader)\n",
        "testdata = [[sample[0].numpy(), sample[1].numpy()] for sample in testdata]\n",
        "test_X = np.vstack([sample[0] for sample in testdata])\n",
        "test_y = np.hstack([sample[1] for sample in testdata])"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ugFXXKS40L21"
      },
      "source": [
        "# Model Definitions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tMvoDB4Pz-fN"
      },
      "source": [
        "## CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dRYFORJP2Pj8"
      },
      "source": [
        "n_epochs = 3\n",
        "batch_size_train = 64\n",
        "batch_size_test = 1000\n",
        "learning_rate = 0.01\n",
        "momentum = 0.5\n",
        "log_interval = 10\n",
        "\n",
        "train_loader = train_dataloader\n",
        "test_loader = test_dataloader"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zw9LQeR8z__y"
      },
      "source": [
        "\"\"\" https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html \"\"\"\n",
        "class ConvolutionalNeuralNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ConvolutionalNeuralNetwork, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
        "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
        "        self.conv2_drop = nn.Dropout2d()\n",
        "        self.fc1 = nn.Linear(320, 50)\n",
        "        self.fc2 = nn.Linear(50, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
        "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
        "        x = x.view(-1, 320)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.dropout(x, training=self.training)\n",
        "        x = self.fc2(x)\n",
        "        return F.log_softmax(x)"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ltsr1tE-3o4Z"
      },
      "source": [
        "### Training and Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xzpMr2uf11se"
      },
      "source": [
        "network = ConvolutionalNeuralNetwork()\n",
        "optimizer = torch.optim.SGD(network.parameters(), lr=learning_rate,\n",
        "                      momentum=momentum)\n",
        "\n",
        "train_losses = []\n",
        "train_counter = []\n",
        "test_losses = []\n",
        "test_counter = [i*len(train_loader.dataset) for i in range(n_epochs + 1)]\n",
        "\n"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cyJtoB0U-FP_"
      },
      "source": [
        "def train(epoch):\n",
        "  network.train()\n",
        "  for batch_idx, (data, target) in enumerate(train_loader):\n",
        "    optimizer.zero_grad()\n",
        "    output = network(data)\n",
        "    loss = F.nll_loss(output, target)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    if batch_idx % log_interval == 0:\n",
        "      print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "        epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "        100. * batch_idx / len(train_loader), loss.item()))\n",
        "      train_losses.append(loss.item())\n",
        "      train_counter.append(\n",
        "        (batch_idx*64) + ((epoch-1)*len(train_loader.dataset)))\n"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4JM1jCBI_my8"
      },
      "source": [
        "def test():\n",
        "  network.eval()\n",
        "  test_loss = 0\n",
        "  correct = 0\n",
        "  with torch.no_grad():\n",
        "    for data, target in test_loader:\n",
        "      output = network(data)\n",
        "      test_loss += F.nll_loss(output, target, size_average=False).item()\n",
        "      pred = output.data.max(1, keepdim=True)[1]\n",
        "      correct += pred.eq(target.data.view_as(pred)).sum()\n",
        "  test_loss /= len(test_loader.dataset)\n",
        "  test_losses.append(test_loss)\n",
        "  print('\\nTest set: Avg. loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "    test_loss, correct, len(test_loader.dataset),\n",
        "    100. * correct / len(test_loader.dataset)))"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KTCnNX61_0p4",
        "outputId": "b4f7e631-13e9-41a3-c26b-51630f391d3f"
      },
      "source": [
        "test()\n",
        "for epoch in range(1, n_epochs + 1):\n",
        "  train(epoch)\n",
        "  test()"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:18: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Avg. loss: 2.3083, Accuracy: 1135/10000 (11%)\n",
            "\n",
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.312635\n",
            "Train Epoch: 1 [1280/60000 (2%)]\tLoss: 2.297971\n",
            "Train Epoch: 1 [2560/60000 (4%)]\tLoss: 2.292659\n",
            "Train Epoch: 1 [3840/60000 (6%)]\tLoss: 2.314809\n",
            "Train Epoch: 1 [5120/60000 (9%)]\tLoss: 2.308498\n",
            "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 2.297230\n",
            "Train Epoch: 1 [7680/60000 (13%)]\tLoss: 2.299668\n",
            "Train Epoch: 1 [8960/60000 (15%)]\tLoss: 2.285244\n",
            "Train Epoch: 1 [10240/60000 (17%)]\tLoss: 2.257514\n",
            "Train Epoch: 1 [11520/60000 (19%)]\tLoss: 2.297477\n",
            "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 2.278899\n",
            "Train Epoch: 1 [14080/60000 (23%)]\tLoss: 2.268862\n",
            "Train Epoch: 1 [15360/60000 (26%)]\tLoss: 2.276213\n",
            "Train Epoch: 1 [16640/60000 (28%)]\tLoss: 2.264648\n",
            "Train Epoch: 1 [17920/60000 (30%)]\tLoss: 2.240462\n",
            "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 2.242015\n",
            "Train Epoch: 1 [20480/60000 (34%)]\tLoss: 2.212231\n",
            "Train Epoch: 1 [21760/60000 (36%)]\tLoss: 2.216612\n",
            "Train Epoch: 1 [23040/60000 (38%)]\tLoss: 2.160372\n",
            "Train Epoch: 1 [24320/60000 (41%)]\tLoss: 2.180161\n",
            "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 2.130684\n",
            "Train Epoch: 1 [26880/60000 (45%)]\tLoss: 2.061678\n",
            "Train Epoch: 1 [28160/60000 (47%)]\tLoss: 2.049945\n",
            "Train Epoch: 1 [29440/60000 (49%)]\tLoss: 1.928521\n",
            "Train Epoch: 1 [30720/60000 (51%)]\tLoss: 1.962791\n",
            "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 1.939228\n",
            "Train Epoch: 1 [33280/60000 (55%)]\tLoss: 1.814679\n",
            "Train Epoch: 1 [34560/60000 (58%)]\tLoss: 1.760368\n",
            "Train Epoch: 1 [35840/60000 (60%)]\tLoss: 1.757623\n",
            "Train Epoch: 1 [37120/60000 (62%)]\tLoss: 1.542679\n",
            "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 1.643214\n",
            "Train Epoch: 1 [39680/60000 (66%)]\tLoss: 1.446385\n",
            "Train Epoch: 1 [40960/60000 (68%)]\tLoss: 1.488082\n",
            "Train Epoch: 1 [42240/60000 (70%)]\tLoss: 1.516345\n",
            "Train Epoch: 1 [43520/60000 (72%)]\tLoss: 1.461912\n",
            "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 1.224353\n",
            "Train Epoch: 1 [46080/60000 (77%)]\tLoss: 1.370016\n",
            "Train Epoch: 1 [47360/60000 (79%)]\tLoss: 1.407498\n",
            "Train Epoch: 1 [48640/60000 (81%)]\tLoss: 1.230604\n",
            "Train Epoch: 1 [49920/60000 (83%)]\tLoss: 1.125020\n",
            "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 1.016177\n",
            "Train Epoch: 1 [52480/60000 (87%)]\tLoss: 1.196049\n",
            "Train Epoch: 1 [53760/60000 (90%)]\tLoss: 1.074719\n",
            "Train Epoch: 1 [55040/60000 (92%)]\tLoss: 0.987003\n",
            "Train Epoch: 1 [56320/60000 (94%)]\tLoss: 0.962898\n",
            "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.992758\n",
            "Train Epoch: 1 [58880/60000 (98%)]\tLoss: 0.926143\n",
            "\n",
            "Test set: Avg. loss: 0.5789, Accuracy: 8488/10000 (85%)\n",
            "\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 1.033654\n",
            "Train Epoch: 2 [1280/60000 (2%)]\tLoss: 0.877920\n",
            "Train Epoch: 2 [2560/60000 (4%)]\tLoss: 0.907638\n",
            "Train Epoch: 2 [3840/60000 (6%)]\tLoss: 0.809735\n",
            "Train Epoch: 2 [5120/60000 (9%)]\tLoss: 0.920533\n",
            "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.961947\n",
            "Train Epoch: 2 [7680/60000 (13%)]\tLoss: 0.793522\n",
            "Train Epoch: 2 [8960/60000 (15%)]\tLoss: 0.820854\n",
            "Train Epoch: 2 [10240/60000 (17%)]\tLoss: 0.744457\n",
            "Train Epoch: 2 [11520/60000 (19%)]\tLoss: 0.844594\n",
            "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.901534\n",
            "Train Epoch: 2 [14080/60000 (23%)]\tLoss: 0.765999\n",
            "Train Epoch: 2 [15360/60000 (26%)]\tLoss: 0.789979\n",
            "Train Epoch: 2 [16640/60000 (28%)]\tLoss: 0.683962\n",
            "Train Epoch: 2 [17920/60000 (30%)]\tLoss: 0.809950\n",
            "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.737954\n",
            "Train Epoch: 2 [20480/60000 (34%)]\tLoss: 0.732090\n",
            "Train Epoch: 2 [21760/60000 (36%)]\tLoss: 0.742803\n",
            "Train Epoch: 2 [23040/60000 (38%)]\tLoss: 0.945562\n",
            "Train Epoch: 2 [24320/60000 (41%)]\tLoss: 0.718473\n",
            "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.733675\n",
            "Train Epoch: 2 [26880/60000 (45%)]\tLoss: 0.800858\n",
            "Train Epoch: 2 [28160/60000 (47%)]\tLoss: 0.710560\n",
            "Train Epoch: 2 [29440/60000 (49%)]\tLoss: 0.679450\n",
            "Train Epoch: 2 [30720/60000 (51%)]\tLoss: 0.665881\n",
            "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.636679\n",
            "Train Epoch: 2 [33280/60000 (55%)]\tLoss: 0.869410\n",
            "Train Epoch: 2 [34560/60000 (58%)]\tLoss: 0.672011\n",
            "Train Epoch: 2 [35840/60000 (60%)]\tLoss: 0.537789\n",
            "Train Epoch: 2 [37120/60000 (62%)]\tLoss: 0.943311\n",
            "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.563910\n",
            "Train Epoch: 2 [39680/60000 (66%)]\tLoss: 0.607250\n",
            "Train Epoch: 2 [40960/60000 (68%)]\tLoss: 0.564345\n",
            "Train Epoch: 2 [42240/60000 (70%)]\tLoss: 0.655555\n",
            "Train Epoch: 2 [43520/60000 (72%)]\tLoss: 0.618502\n",
            "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.646590\n",
            "Train Epoch: 2 [46080/60000 (77%)]\tLoss: 0.793213\n",
            "Train Epoch: 2 [47360/60000 (79%)]\tLoss: 0.627464\n",
            "Train Epoch: 2 [48640/60000 (81%)]\tLoss: 0.719866\n",
            "Train Epoch: 2 [49920/60000 (83%)]\tLoss: 0.764267\n",
            "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.562059\n",
            "Train Epoch: 2 [52480/60000 (87%)]\tLoss: 0.541238\n",
            "Train Epoch: 2 [53760/60000 (90%)]\tLoss: 0.588896\n",
            "Train Epoch: 2 [55040/60000 (92%)]\tLoss: 0.584868\n",
            "Train Epoch: 2 [56320/60000 (94%)]\tLoss: 0.609632\n",
            "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.604822\n",
            "Train Epoch: 2 [58880/60000 (98%)]\tLoss: 0.708077\n",
            "\n",
            "Test set: Avg. loss: 0.3217, Accuracy: 9108/10000 (91%)\n",
            "\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.707732\n",
            "Train Epoch: 3 [1280/60000 (2%)]\tLoss: 0.490232\n",
            "Train Epoch: 3 [2560/60000 (4%)]\tLoss: 0.595666\n",
            "Train Epoch: 3 [3840/60000 (6%)]\tLoss: 0.717787\n",
            "Train Epoch: 3 [5120/60000 (9%)]\tLoss: 0.664791\n",
            "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.645749\n",
            "Train Epoch: 3 [7680/60000 (13%)]\tLoss: 0.487113\n",
            "Train Epoch: 3 [8960/60000 (15%)]\tLoss: 0.579622\n",
            "Train Epoch: 3 [10240/60000 (17%)]\tLoss: 0.379130\n",
            "Train Epoch: 3 [11520/60000 (19%)]\tLoss: 0.605914\n",
            "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.541411\n",
            "Train Epoch: 3 [14080/60000 (23%)]\tLoss: 0.560008\n",
            "Train Epoch: 3 [15360/60000 (26%)]\tLoss: 0.527066\n",
            "Train Epoch: 3 [16640/60000 (28%)]\tLoss: 0.514869\n",
            "Train Epoch: 3 [17920/60000 (30%)]\tLoss: 0.516589\n",
            "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.655106\n",
            "Train Epoch: 3 [20480/60000 (34%)]\tLoss: 0.515013\n",
            "Train Epoch: 3 [21760/60000 (36%)]\tLoss: 0.729688\n",
            "Train Epoch: 3 [23040/60000 (38%)]\tLoss: 0.414870\n",
            "Train Epoch: 3 [24320/60000 (41%)]\tLoss: 0.754601\n",
            "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.557487\n",
            "Train Epoch: 3 [26880/60000 (45%)]\tLoss: 0.569070\n",
            "Train Epoch: 3 [28160/60000 (47%)]\tLoss: 0.444246\n",
            "Train Epoch: 3 [29440/60000 (49%)]\tLoss: 0.671529\n",
            "Train Epoch: 3 [30720/60000 (51%)]\tLoss: 0.545418\n",
            "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.668446\n",
            "Train Epoch: 3 [33280/60000 (55%)]\tLoss: 0.453608\n",
            "Train Epoch: 3 [34560/60000 (58%)]\tLoss: 0.483397\n",
            "Train Epoch: 3 [35840/60000 (60%)]\tLoss: 0.746683\n",
            "Train Epoch: 3 [37120/60000 (62%)]\tLoss: 0.657419\n",
            "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.478708\n",
            "Train Epoch: 3 [39680/60000 (66%)]\tLoss: 0.566606\n",
            "Train Epoch: 3 [40960/60000 (68%)]\tLoss: 0.484932\n",
            "Train Epoch: 3 [42240/60000 (70%)]\tLoss: 0.595079\n",
            "Train Epoch: 3 [43520/60000 (72%)]\tLoss: 0.557115\n",
            "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.732483\n",
            "Train Epoch: 3 [46080/60000 (77%)]\tLoss: 0.691381\n",
            "Train Epoch: 3 [47360/60000 (79%)]\tLoss: 0.607815\n",
            "Train Epoch: 3 [48640/60000 (81%)]\tLoss: 0.589313\n",
            "Train Epoch: 3 [49920/60000 (83%)]\tLoss: 0.466506\n",
            "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.562021\n",
            "Train Epoch: 3 [52480/60000 (87%)]\tLoss: 0.507836\n",
            "Train Epoch: 3 [53760/60000 (90%)]\tLoss: 0.591189\n",
            "Train Epoch: 3 [55040/60000 (92%)]\tLoss: 0.477625\n",
            "Train Epoch: 3 [56320/60000 (94%)]\tLoss: 0.480731\n",
            "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.475883\n",
            "Train Epoch: 3 [58880/60000 (98%)]\tLoss: 0.444088\n",
            "\n",
            "Test set: Avg. loss: 0.2388, Accuracy: 9321/10000 (93%)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BUcyJEON6A_p",
        "outputId": "3b15b109-c1ec-4573-e307-e16d17118f9d"
      },
      "source": [
        "#cnn = train_one_cnn()\n",
        "evaluate_cnn(cnn)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:18: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 65 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kAg4fEcS9156"
      },
      "source": [
        "## VAE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DoZjwrH3xpei"
      },
      "source": [
        "#SEED = 100\n",
        "\n",
        "LAT_DIM = 2\n",
        "EPOCH_NUM = 50\n",
        "CAPACITY = 64\n",
        "LRN_RATE = 1e-3\n",
        "VAR_BETA = 1\n",
        "\n",
        "KERN_SIZE = 4\n",
        "STRIDE = 2\n",
        "PAD = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UkcWN5LXyCEo"
      },
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Encoder, self).__init__()\n",
        "        \n",
        "        # CAPACITY * 14 * 14\n",
        "        self.conv1 = nn.Conv2d(\n",
        "            in_channels = 1,\n",
        "            out_channels = CAPACITY,\n",
        "            kernel_size = KERN_SIZE,\n",
        "            stride = STRIDE,\n",
        "            padding = PAD,\n",
        "        )\n",
        "        # CAPACITY * 7 * 7\n",
        "        self.conv2 = nn.Conv2d(\n",
        "            in_channels = CAPACITY,\n",
        "            out_channels = CAPACITY * 2,\n",
        "            kernel_size = KERN_SIZE,\n",
        "            stride = STRIDE,\n",
        "            padding = PAD,\n",
        "        )\n",
        "        self.fc_mu = nn.Linear(\n",
        "            in_features = CAPACITY * 2 * 7 * 7,\n",
        "            out_features = LAT_DIM,\n",
        "        )\n",
        "        self.fc_logvar = nn.Linear(\n",
        "            in_features = CAPACITY * 2 * 7 * 7,\n",
        "            out_features = LAT_DIM,\n",
        "        )\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv2(\n",
        "            F.relu(self.conv1(x))\n",
        "        ))\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x_mu = self.fc_mu(x)\n",
        "        x_logvar = self.fc_logvar(x)\n",
        "        return x_mu, x_logvar"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "35jQ8f41zRFg"
      },
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Decoder, self).__init__()\n",
        "        \n",
        "        self.fc = nn.Linear(\n",
        "            in_features = LAT_DIM,\n",
        "            out_features = CAPACITY * 2 * 7 * 7,\n",
        "        )\n",
        "        self.conv2 = nn.ConvTranspose2d(\n",
        "            in_channels = CAPACITY * 2,\n",
        "            out_channels = CAPACITY,\n",
        "            kernel_size = KERN_SIZE,\n",
        "            stride = STRIDE,\n",
        "            padding = PAD,\n",
        "        )\n",
        "        self.conv1 = nn.ConvTranspose2d(\n",
        "            in_channels = CAPACITY,\n",
        "            out_channels = 1,\n",
        "            kernel_size = KERN_SIZE,\n",
        "            stride = STRIDE,\n",
        "            padding = PAD,\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc(x)\n",
        "        return torch.sigmoid(self.conv1(\n",
        "                F.relu(self.conv2(\n",
        "                    x.view(x.size(0), CAPACITY * 2, 7, 7)\n",
        "            ))\n",
        "        ))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PCQPtw5a3DQI"
      },
      "source": [
        "class VariationalAutoencoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(VariationalAutoencoder, self).__init__()\n",
        "        \n",
        "        self.encoder = Encoder()\n",
        "        self.decoder = Decoder()\n",
        "\n",
        "    def forward(self, x):\n",
        "        latent_mu, latent_logvar = self.encoder(x)\n",
        "        latent = self.latent_sample(latent_mu, latent_logvar)\n",
        "        x_recon = self.decoder(latent)\n",
        "        return x_recon, latent_mu, latent_logvar\n",
        "\n",
        "    def latent_sample(self, mu, logvar):\n",
        "        if self.training:\n",
        "            # the reparameterization trick\n",
        "            std = logvar.mul(0.5).exp_()\n",
        "            eps = torch.empty_like(std).normal_()\n",
        "            return eps.mul(std).add_(mu)\n",
        "        else:\n",
        "            return mu"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e2CrBYQU4e8r"
      },
      "source": [
        "def reconstruction_error(recon_x, x):\n",
        "    return F.binary_cross_entropy(\n",
        "        recon_x.view(-1, 784),\n",
        "        x.view(-1, 784),\n",
        "        reduction = \"sum\",\n",
        "    )\n",
        "\n",
        "def vae_loss(recon_loss, mu, logvar):\n",
        "    kl_divergence = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
        "    return recon_loss + VAR_BETA * kl_divergence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N7XQuBW63DmN"
      },
      "source": [
        "### Training and Evaluation\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2FVd05s4I4YM"
      },
      "source": [
        "def plot_loss(train_losses, test_losses):\n",
        "    plt.ion()\n",
        "\n",
        "    plotlabels = [\"Total error\", \"Reconstruction error\"]\n",
        "    \n",
        "    ncols = 2\n",
        "    fig, ax = plt.subplots(ncols = ncols, figsize = (9, 2.5))\n",
        "    \n",
        "    for i in range(2): \n",
        "        ax[i].plot(train_losses[i], c = \"blue\", label = \"training\")\n",
        "        ax[i].plot(test_losses[i], c = \"red\", label = \"test\")\n",
        "            \n",
        "        ax[i].set_title(plotlabels[i])\n",
        "        \n",
        "    plt.xlabel('Epochs')\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel(y)\n",
        "    plt.legend()\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "isT5TzCPJEE1"
      },
      "source": [
        "def eval_model(vae):\n",
        "    vae.eval()\n",
        "    \n",
        "    test_loss_avg, test_recon_loss_avg, num_batches = 0, 0, 0\n",
        "    sum = 0\n",
        "    for image_batch, _ in test_dataloader:\n",
        "        \n",
        "        with torch.no_grad():\n",
        "        \n",
        "            image_batch = image_batch.to(device)\n",
        "    \n",
        "            # vae reconstruction\n",
        "            image_batch_recon, latent_mu, latent_logvar = vae(image_batch)\n",
        "    \n",
        "            # reconstruction error\n",
        "            recon_loss = reconstruction_error(image_batch_recon, image_batch)\n",
        "            loss = vae_loss(recon_loss, latent_mu, latent_logvar)\n",
        "    \n",
        "            test_recon_loss_avg += recon_loss\n",
        "            test_loss_avg += loss.item()\n",
        "            num_batches += 1\n",
        "        \n",
        "    test_recon_loss_avg /= num_batches\n",
        "    test_loss_avg /= num_batches\n",
        "\n",
        "    return test_recon_loss_avg, test_loss_avg\n",
        "    #print('average reconstruction error: %f' % (test_recon_loss_avg))\n",
        "    #print('average error: %f' % (test_loss_avg))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lb5IpN6M3KKk"
      },
      "source": [
        "def train_one_model(evaluate = False):\n",
        "    \"\"\" Creates and trains one VAE model.\n",
        "\n",
        "    Args:\n",
        "        evaluate: Whether or not to evaluate model during training.\n",
        "\n",
        "    Returns:\n",
        "        Tuple containing the trained model, average training reconstruction\n",
        "        error, average total training error, average testing reconstruction\n",
        "        error, and average total testing error.\n",
        "    \"\"\"\n",
        "\n",
        "    #torch.cuda.manual_seed(SEED)\n",
        "    vae = VariationalAutoencoder()\n",
        "    vae = vae.to(device)\n",
        "    \n",
        "    num_params = sum(p.numel() for p in vae.parameters() if p.requires_grad)\n",
        "    print('Number of parameters: %d' % num_params)\n",
        "    \n",
        "    optimizer = torch.optim.Adam(\n",
        "        params = vae.parameters(),\n",
        "        lr = LRN_RATE,\n",
        "        weight_decay = 1e-5,\n",
        "    )\n",
        "    \n",
        "    # set to training mode\n",
        "    vae.train()\n",
        "    \n",
        "    if evaluate:\n",
        "        train_recon_loss, train_loss = [], []\n",
        "        test_recon_loss, test_loss = [], []\n",
        "    \n",
        "    print(\"Training: \", end = \"\")\n",
        "    for epoch in range(EPOCH_NUM):\n",
        "        if evaluate:\n",
        "            train_loss.append(0)\n",
        "            train_recon_loss.append(0)\n",
        "        num_batches = 0\n",
        "        \n",
        "        for image_batch, _ in train_dataloader:\n",
        "            \n",
        "            image_batch = rot_transform(image_batch)\n",
        "            image_batch = image_batch.to(device)\n",
        "    \n",
        "            # vae reconstruction\n",
        "            image_batch_recon, latent_mu, latent_logvar = vae(image_batch)\n",
        "            \n",
        "            # reconstruction error\n",
        "            recon_loss = reconstruction_error(image_batch_recon, image_batch)\n",
        "            loss = vae_loss(recon_loss, latent_mu, latent_logvar)\n",
        "            \n",
        "            # backpropagation\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            \n",
        "            # one step of the optmizer (using the gradients from backpropagation)\n",
        "            optimizer.step()\n",
        "            \n",
        "            if evaluate:\n",
        "                train_loss[-1] += loss.item()\n",
        "                train_recon_loss[-1] += recon_loss\n",
        "                \n",
        "            num_batches += 1\n",
        "            \n",
        "        if evaluate:\n",
        "            train_loss[-1] /= num_batches\n",
        "            train_recon_loss[-1] /= num_batches\n",
        "        \n",
        "            recon_loss_avg, loss_avg = eval_model(vae)\n",
        "            test_recon_loss.append(recon_loss_avg)\n",
        "            test_loss.append(loss_avg)\n",
        "            vae.train()\n",
        "        \n",
        "        print(\"%d, \" % (epoch+1), end = \"\")\n",
        "        \n",
        "    print()\n",
        "    if evaluate: \n",
        "        plot_loss(\n",
        "            [train_loss, train_recon_loss],\n",
        "            [test_loss, test_recon_loss],\n",
        "        )\n",
        "        \n",
        "    return vae"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "idP_RI6bBttt"
      },
      "source": [
        "def train_and_test_models(\n",
        "    n, gamma_matrix, alpha_matrix, beta_matrix, evaluate = False,\n",
        "):\n",
        "    \"\"\"\n",
        "    Train n models and compute the MNIST heterogeneities on the models.\n",
        "\n",
        "    Returns:\n",
        "        Heterogeneity \"matrices\" that are lists of np arrrays.\n",
        "        matrix[i] is the heterogeneity array for vae_i\n",
        "        matrix[i][j] is the heterogeneity for digit_j for vae_i\n",
        "    \"\"\"\n",
        "    for _ in range(n):\n",
        "        vae = train_one_model(evaluate = evaluate)\n",
        "        \n",
        "        gammas, alphas, betas = calculate_rrh(vae)\n",
        "        gamma_matrix.append(gammas)\n",
        "        alpha_matrix.append(alphas)\n",
        "        beta_matrix.append(betas)\n",
        "    return gamma_matrix, alpha_matrix, beta_matrix\n",
        "\n",
        "def plot_rrh_matrices(gamma_matrix, alpha_matrix, beta_matrix):\n",
        "    gamma_avg = het_avg(gamma_matrix)\n",
        "    alpha_avg = het_avg(alpha_matrix)\n",
        "    beta_avg = het_avg(beta_matrix)\n",
        "    \n",
        "    gamma_sigma = het_sigma(gamma_matrix)\n",
        "    alpha_sigma = het_sigma(alpha_matrix)\n",
        "    beta_sigma = het_sigma(beta_matrix)\n",
        "    \n",
        "    plot_rrh(\n",
        "        gamma_avg, alpha_avg, beta_avg,\n",
        "        sigmas = [gamma_sigma, alpha_sigma, beta_sigma],\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bxImy1XR6FHR"
      },
      "source": [
        "## RRH for Gaussian Mixtures"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2H2L9XvS6Kwj"
      },
      "source": [
        "def mvn_renyi(C, q=1):\n",
        "    \"\"\" Computes the RÃ©nyi heterogeneity for a multivariate Gaussian \n",
        "    Arguments: \n",
        "        C: `ndarray((n,n))`. Covariance matrix\n",
        "        q: `0<float`. Order of the heterogeneity\n",
        "    Returns: \n",
        "        `float`\n",
        "    \"\"\"\n",
        "    n = C.shape[0]\n",
        "    SqrtDetC = np.sqrt(np.linalg.det(C))\n",
        "    if q == 1: \n",
        "        out = (2*np.pi*np.e)**(n/2) * SqrtDetC\n",
        "    elif q == np.inf: \n",
        "        out = (2*np.pi)**(n/2) * SqrtDetC\n",
        "    elif q!=1 and q!=0 and q!=np.inf:\n",
        "        out = ((2*np.pi)**(n/2))*(q**(n/(2*(q-1))))*SqrtDetC\n",
        "    return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TkLYVMBu6fDn"
      },
      "source": [
        "def mvn_renyi_alpha(C,  q=1):\n",
        "    \"\"\" Computes the alpha-heterogeneity for a Gaussian mixture where each sample has equal weight\n",
        "\n",
        "    Arguments: \n",
        "\n",
        "        cov: `ndarray((nsamples, n, n))`. Covariance matrices \n",
        "        q: `0<float`. Order of the heterogeneity metric\n",
        "\n",
        "    Returns: \n",
        "\n",
        "        `float`. The alpha-heterogeneity\n",
        "    \"\"\"\n",
        "    K, n, _ = C.shape\n",
        "    p = np.repeat(1/K, K)\n",
        "    if q == 1:\n",
        "        out = np.exp((n + np.sum(p*np.log(np.linalg.det(2*np.pi*C))))/2)\n",
        "    elif q!=np.inf and q!=1 and q!=0:\n",
        "        wbar = (p**q)/np.sum(p**q)\n",
        "        out = ((2*np.pi)**(n/2))*np.sum(wbar*np.sqrt(np.linalg.det(C)))/(q**(n/2))**(1/(1-q))\n",
        "    return out\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4aDzvMEx_X9r"
      },
      "source": [
        "def scale_to_cov(scales):\n",
        "    return np.vstack([np.expand_dims(np.diagflat(s), 0) for s in scales])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DS7dTSHl_e2i"
      },
      "source": [
        "def pool_covariance(means, covs):\n",
        "    K = covs.shape[0] \n",
        "    p = np.repeat(1/K, K)\n",
        "    cov_ = np.einsum('ijk,i->jk', covs, p) + np.einsum('ij,ik,i->jk', means, means, p)\n",
        "    mu_ = np.einsum('ij,i->j', means, p)\n",
        "    return cov_ - np.einsum('i,j->ij', mu_, mu_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RG67lA7u6pAY"
      },
      "source": [
        "### Computation and plotting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IinU-xeM6fg_"
      },
      "source": [
        "def calculate_rrh(vae, X = train_X, y = train_y):\n",
        "    gammas, alphas, betas = [], [], []\n",
        "    for i in range(10):\n",
        "        mu, logvar = vae.encoder(torch.Tensor(X[y == i]).to(device))\n",
        "        loc = mu.cpu().detach().numpy()\n",
        "        scale = logvar.exp().cpu().detach().numpy()\n",
        "        cov = scale_to_cov(scale)\n",
        "        gamma = mvn_renyi(pool_covariance(loc, cov), q=1)\n",
        "        alpha = mvn_renyi_alpha(cov,q=1)\n",
        "        beta = gamma/alpha\n",
        "        gammas.append(gamma)\n",
        "        alphas.append(alpha)\n",
        "        betas.append(beta)\n",
        "    return np.array(gammas), np.array(alphas), np.array(betas)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xcRWRha365r-"
      },
      "source": [
        "def plot_rrh(gammas, alphas, betas, sigmas = None):\n",
        "    if not (len(gammas) == len(alphas) or len(gammas) == len(betas)):\n",
        "        sys.exit(\"Mismatched matrix size\")\n",
        "    n = len(gammas)\n",
        "    hetvalues = [gammas, alphas, betas]\n",
        "    plotlabels = [r\"Pooled\", r\"Within-Observation\", r\"Between-Observation\"]\n",
        "    \n",
        "    fig, ax = plt.subplots(ncols=3, figsize=(9, 2.5))\n",
        "    ax[0].set_ylabel(\"Heterogeneity\")\n",
        "    \n",
        "    for i in range(3): \n",
        "        ax[i].set_title(plotlabels[i])\n",
        "        ax[i].set_xlabel(\"Digit\")\n",
        "        ax[i].set_xticks(np.arange(10))\n",
        "        ax[i].set_xticklabels(np.arange(10))\n",
        "        ax[i].bar(\n",
        "            np.arange(10),\n",
        "            hetvalues[i],\n",
        "            facecolor = plt.get_cmap(\"Greys\")(0.4), \n",
        "            edgecolor = \"black\",\n",
        "        )\n",
        "        if not sigmas == None:\n",
        "            ax[i].errorbar(\n",
        "                np.arange(10),\n",
        "                hetvalues[i],\n",
        "                yerr = sigmas[i],\n",
        "                fmt = \"none\",\n",
        "                ecolor = \"r\",\n",
        "                capsize = 3,\n",
        "                label = \"std deviation\",\n",
        "            )\n",
        "            ax[i].errorbar(\n",
        "                np.arange(10),\n",
        "                hetvalues[i],\n",
        "                yerr = sigmas[i] / np.sqrt(n),\n",
        "                fmt = \"none\",\n",
        "                ecolor = \"b\",\n",
        "                capsize = 3,\n",
        "                label = \"std error\",\n",
        "            )\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    #plt.savefig(\"digit-class-heterogeneity.pdf\", bbox_inches=\"tight\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mOOtu98Jv1-_"
      },
      "source": [
        "def het_sigma(matrix, avg = None):\n",
        "    if avg == None:\n",
        "        avg = het_avg(matrix)\n",
        "    n = len(matrix)\n",
        "    mse = (matrix[0] - avg) ** 2\n",
        "    for i in range(1, n):\n",
        "        mse += (matrix[i] - avg) ** 2\n",
        "    return np.sqrt(mse / n)\n",
        "\n",
        "def het_sum(matrix):\n",
        "    sum = matrix[0] + matrix[1]\n",
        "    for i in range(2, len(matrix)):\n",
        "        sum += matrix[i]\n",
        "    return sum\n",
        "\n",
        "def het_avg(matrix):\n",
        "    return het_sum(matrix) / len(matrix)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eM3hF-q0VipP"
      },
      "source": [
        "# Experiments"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "bzmQvee5qsLp",
        "outputId": "16e71aba-8c45-47e8-e090-572981c08f14"
      },
      "source": [
        "\"\"\"\n",
        "N = 1\n",
        "n = 5\n",
        "gamma_matrix, alpha_matrix, beta_matrix = [], [], []\n",
        "for _ in range(N):\n",
        "    gamma_matrix, alpha_matrix, beta_matrix = train_and_test_models(\n",
        "        n, gamma_matrix, alpha_matrix, beta_matrix, evaluate = True,\n",
        "    )\n",
        "    plot_rrh_matrices(gamma_matrix, alpha_matrix, beta_matrix)\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nN = 1\\nn = 5\\ngamma_matrix, alpha_matrix, beta_matrix = [], [], []\\nfor _ in range(N):\\n    gamma_matrix, alpha_matrix, beta_matrix = train_and_test_models(\\n        n, gamma_matrix, alpha_matrix, beta_matrix, evaluate = True,\\n    )\\n    plot_rrh_matrices(gamma_matrix, alpha_matrix, beta_matrix)\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        },
        "id": "86cSR8lZ4AK7",
        "outputId": "c3ab9ab6-d65c-4d6b-b4aa-a1d757dfc8ee"
      },
      "source": [
        "vae1 = train_one_model()\n",
        "vae2 = train_one_model()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of parameters: 308357\n",
            "Training: 1, 2, 3, 4, "
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-dddc9d0f330d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvae1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_one_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mvae2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_one_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-baaa6e65c826>\u001b[0m in \u001b[0;36mtrain_one_model\u001b[0;34m(evaluate)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0;31m# one step of the optmizer (using the gradients from backpropagation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    117\u001b[0m                    \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m                    \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'weight_decay'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m                    \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'eps'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m                    )\n\u001b[1;32m    121\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/optim/functional.py\u001b[0m in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps)\u001b[0m\n\u001b[1;32m     92\u001b[0m             \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmax_exp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m             \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0mstep_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lvx8i8Ct9yMR"
      },
      "source": [
        "## Load, Evaluate, and Plot RRH for Pre-Trained VAE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vNRYGlvQ5O77"
      },
      "source": [
        "def load_pretrained_vae():\n",
        "    pretrained_vae = VariationalAutoencoder()\n",
        "    pretrained_vae = pretrained_vae.to(device)\n",
        "    \n",
        "    filename = 'vae_2d.pth'\n",
        "    \n",
        "    if not os.path.isdir('./pretrained'):\n",
        "        os.makedirs('./pretrained')\n",
        "    urllib.request.urlretrieve(\n",
        "        \"http://geometry.cs.ucl.ac.uk/creativeai/pretrained/\" + filename,\n",
        "        \"./pretrained/\" + filename,\n",
        "    )\n",
        "    pretrained_vae.load_state_dict(torch.load('./pretrained/' + filename))\n",
        "    return pretrained_vae"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nRS4NG0mJJZY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c96140ee-ff98-4e1a-8ab9-31e20d76573f"
      },
      "source": [
        "pretrained_vae = load_pretrained_vae()\n",
        "eval_model(pretrained_vae)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(18493.6641, device='cuda:0'), 19294.807005290742)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_nN1Kftyh42Z",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "outputId": "11033c6d-1586-4c2d-ddef-8da7f60e5d74"
      },
      "source": [
        "gammas, alphas, betas = calculate_rrh(pretrained_vae)\n",
        "plot_rrh(gammas, alphas, betas)\n",
        "\n",
        "gammas, alphas, betas = calculate_rrh(pretrained_vae, X = test_X, y = test_y)\n",
        "plot_rrh(gammas, alphas, betas)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 648x180 with 3 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 648x180 with 3 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vzodKmcX0SLi"
      },
      "source": [
        "def to_img(x):\n",
        "    x = x.clamp(0, 1)\n",
        "    return x\n",
        "\n",
        "def show_image(img):\n",
        "    img = to_img(img)\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "\n",
        "def visualize_latent_space(vae):\n",
        "    vae.eval()\n",
        "\n",
        "    bound = 2.5\n",
        "    nsteps = 20 \n",
        "    with torch.no_grad():\n",
        "        latent_x = np.linspace(-bound,bound,nsteps)\n",
        "        latent_y = np.linspace(-bound,bound,nsteps)\n",
        "        latents = torch.FloatTensor(len(latent_x), len(latent_y), 2)\n",
        "        for i, lx in enumerate(latent_x):\n",
        "            for j, ly in enumerate(latent_y):\n",
        "                latents[j, i, 0] = lx\n",
        "                latents[j, i, 1] = ly\n",
        "        latents = latents.view(-1, 2) # flatten grid into a batch\n",
        "    \n",
        "        # reconstruct images from the latent vectors\n",
        "        latents = latents.to(device)\n",
        "        image_recon = vae.decoder(latents)\n",
        "        image_recon = image_recon.cpu()\n",
        "    \n",
        "        fig, ax = plt.subplots(figsize=(10, 10))\n",
        "        show_image(\n",
        "            torchvision.utils.make_grid(\n",
        "                image_recon.data[:int(nsteps**2)], nsteps, 5,\n",
        "            )\n",
        "        )\n",
        "        ax.set_xticks([]); ax.set_xticklabels([])\n",
        "        ax.set_yticks([]); ax.set_yticklabels([])\n",
        "        #plt.savefig(\"latent-space-map.pdf\", bbox_inches=\"tight\")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8v0TSx231Las"
      },
      "source": [
        "visualize_latent_space(vae1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0_NVuvet7_e4"
      },
      "source": [
        "visualize_latent_space(vae2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LsksiYr20gME"
      },
      "source": [
        "visualize_latent_space(pretrained_vae)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fa8BsW-sxvOf"
      },
      "source": [
        "def visualise_output(images, model, title = \"DEFAULT\"):\n",
        "\n",
        "    with torch.no_grad():\n",
        "    \n",
        "        images = images.to(device)\n",
        "        images, _, _ = model(images)\n",
        "        images = images.cpu()\n",
        "        images = to_img(images)\n",
        "        np_imagegrid = torchvision.utils.make_grid(images[0:IMG_NUM], WIDTH, HEIGHT).numpy()\n",
        "        plt.imshow(np.transpose(np_imagegrid, (1, 2, 0)))\n",
        "        plt.title(title)\n",
        "        plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dxYy03Fdtlwn"
      },
      "source": [
        "IMG_NUM = 100\n",
        "WIDTH = 10\n",
        "HEIGHT = 10\n",
        "\n",
        "sns.set(style = \"dark\")\n",
        "\n",
        "images, labels = iter(test_dataloader).next()\n",
        "\n",
        "# First visualise the original images\n",
        "print('Original images')\n",
        "show_image(torchvision.utils.make_grid(images[0:IMG_NUM], WIDTH, HEIGHT))\n",
        "plt.title(\"Original\")\n",
        "plt.show()\n",
        "\n",
        "\n",
        "visualise_output(images, vae1, title = \"VAE 1\")\n",
        "\n",
        "visualise_output(images, vae2, title = \"VAE 2\")\n",
        "\n",
        "visualise_output(images, pretrained_vae, title = \"Pretrained VAE\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zjWWbUCA0oKk"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}